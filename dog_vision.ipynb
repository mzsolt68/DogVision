{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uzvP409-BkDkfGOrePIsP57TDqw_57Kb",
      "authorship_tag": "ABX9TyN7yZzBw4pkgxU15nI3sE2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzsolt68/DogVision/blob/main/dog_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-end Multi-class Dog Breed Classification (v2)\n",
        "\n",
        "Building an end-to-end multi-class image classifier using TensorFlow\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Identifying the breed of a dog from a given image\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "We're going to use the Stanford Dogs dataset, which is available from several sources:\n",
        "* The original project website: http://vision.stanford.edu/aditya86/ImageNetDogs/\n",
        "* Inside the Tensorflow datasets: https://www.tensorflow.org/datasets/catalog/stanford_dogs\n",
        "* On Kaggle: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
        "\n",
        "## 3. Using the data\n",
        "\n",
        "To make sure we don't have to download the data every time we come back to Colab:\n",
        "* Download the data to the attached Google Drive if it doesn't already exists\n",
        "* Copy the data to the Google drive if it isn't already there\n",
        "* If the data already exists on Google Drive We'll import it\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Some information about the data:\n",
        "* We are dealing with unstructured data (images), so it is probably best we use deeep learning/transfer learning.\n",
        "* There are 120 breeds of dogs, this means there are 120 different classes).\n",
        "* Around 10,000+ images in the training set (these images have labels)\n",
        "* Around 10,000+ images in the test set\n"
      ],
      "metadata": {
        "id": "0VwaLo79sNPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick timestamp\n",
        "import datetime\n",
        "print(f\"Notebook last run: {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "id": "Y2DNaKLF_Dye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e814d7d6-693f-4255-a71e-68eddd917179"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook last run: 2025-05-29 14:37:43.922196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and check if we have GPU access\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "device_list = tf.config.list_physical_devices()\n",
        "if \"GPU\" in [device.device_type for device in device_list]:\n",
        "  print(f\"[INFO] TensorFlow has GPU available to use.\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")\n",
        "else:\n",
        "  print(f\"[INFO] TensorFlow does not have GPU available to use. Models may take a while to train.\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")"
      ],
      "metadata": {
        "id": "lbd2DEh0_Xu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the data\n",
        "Check if the target files exist in Google Drive and copy them to Colab. If the files doesn't exist, download them."
      ],
      "metadata": {
        "id": "0OYi08W4_7v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive (this will bring up a pop-up to sign-in/authenticate)\n",
        "# Note: This step is specifically for Google Colab, if you're working locally, you may need a different setup\n",
        "# drive.mount(\"/content/drive\")\n",
        "\n",
        "# 2. Setup constants\n",
        "# Note: For constants like this, you'll often see them created as variables with all capitals\n",
        "TARGET_DRIVE_PATH = Path(\"drive/MyDrive/Dog_Vision/Data\")\n",
        "TARGET_FILES = [\"images.tar\", \"annotation.tar\", \"lists.tar\"]\n",
        "TARGET_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs\"\n",
        "\n",
        "# 3. Setup local path\n",
        "local_dir = Path(\"dog_vision_data\")\n",
        "\n",
        "# 4. Check if the target files exist in Google Drive, if so, copy them to Google Colab\n",
        "if all((TARGET_DRIVE_PATH / file).is_file() for file in TARGET_FILES):\n",
        "  print(f\"[INFO] Copying Dog Vision files from Google Drive to local directory...\")\n",
        "  print(f\"[INFO] Source dir: {TARGET_DRIVE_PATH} -> Target dir: {local_dir}\")\n",
        "  !cp -r {TARGET_DRIVE_PATH} {local_dir}\n",
        "  print(\"[INFO] Good to go!\")\n",
        "\n",
        "else:\n",
        "  # 5. If the files don't exist in Google Drive, download them\n",
        "  print(f\"[INFO] Target files not found in Google Drive.\")\n",
        "  print(f\"[INFO] Downloading the target files... this shouldn't take too long...\")\n",
        "  for file in TARGET_FILES:\n",
        "    # wget is short for \"world wide web get\", as in \"get a file from the web\"\n",
        "    # -nc or --no-clobber = don't download files that already exist locally\n",
        "    # -P = save the target file to a specified prefix, in our case, local_dir\n",
        "    !wget -nc {TARGET_URL}/{file} -P {local_dir} # the \"!\" means to execute the command on the command line rather than in Python\n",
        "\n",
        "  print(f\"[INFO] Saving the target files to Google Drive, so they can be loaded later...\")\n",
        "\n",
        "  # 6. Ensure target directory in Google Drive exists\n",
        "  TARGET_DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # 7. Copy downloaded files to Google Drive (so we can use them later and not have to re-download them)\n",
        "  !cp -r {local_dir}/* {TARGET_DRIVE_PATH}/"
      ],
      "metadata": {
        "id": "eHwSjZ_6ABjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the files are exist\n",
        "if local_dir.exists():\n",
        "  print(str(local_dir) + \"/\")\n",
        "  for item in local_dir.iterdir():\n",
        "    print(\"  \", item.name)"
      ],
      "metadata": {
        "id": "_jQbOkfWB6p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untar the images, notes/tags\n",
        "!tar -xf {local_dir}/images.tar -C {local_dir}\n",
        "!tar -xf {local_dir}/annotation.tar -C {local_dir}\n",
        "!tar -xf {local_dir}/lists.tar -C {local_dir}\n"
      ],
      "metadata": {
        "id": "J6lD7f_ICqt8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got some new files.\n",
        "Specifically:\n",
        "\n",
        "* `train_list.mat` - a list of all the training set images.\n",
        "* `test_list.mat` - a list of all the testing set images.\n",
        "* `Images/` - a folder containing all of the images of dogs.\n",
        "* `Annotation/` - a folder containing all of the annotations for each image.\n",
        "* `file_list.mat` - a list of all the files (training and test list combined).\n"
      ],
      "metadata": {
        "id": "D2NzvDlJDoxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data\n",
        "Before we build a model, it's good to explore the data to see what kind of data we're working with. For example:\n",
        "* **Check at least 100+ random samples** if you have a large dataset.\n",
        "* **Visualize!**\n",
        "* **Check the distribution and other statistics.** How many samples are there? In a classification problem, how many classes and labels per class are there? etc."
      ],
      "metadata": {
        "id": "81MY3j-dFu6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the files lists"
      ],
      "metadata": {
        "id": "E0vUvt97MgSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the MATLAB files\n",
        "import scipy\n",
        "\n",
        "# Open lists of train and test .mat\n",
        "train_list = scipy.io.loadmat(Path(local_dir, \"train_list.mat\"))\n",
        "test_list = scipy.io.loadmat(Path(local_dir, \"test_list.mat\"))\n",
        "file_list = scipy.io.loadmat(Path(local_dir, \"file_list.mat\"))\n",
        "\n",
        "# Let's inspect the output and type of the train_list\n",
        "train_list, type(train_list)"
      ],
      "metadata": {
        "id": "y6uzipa-EOeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the keys of the train_list dictionary\n",
        "train_list.keys()"
      ],
      "metadata": {
        "id": "v5TV2aFzKXAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of the file_list key\n",
        "print(f\"Number of files in training list: {len(train_list['file_list'])}\")\n",
        "print(f\"Number of files in testing list: {len(test_list['file_list'])}\")\n",
        "print(f\"Number of files in full list: {len(file_list['file_list'])}\")"
      ],
      "metadata": {
        "id": "RYheiPqvLwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 20580 images total splitted in 60/40 ratio between train and test."
      ],
      "metadata": {
        "id": "j4l5Zl_xMDuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the file_list key more\n",
        "train_list['file_list']\n"
      ],
      "metadata": {
        "id": "Hvf96EWAMsfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single filename\n",
        "train_list['file_list'][0][0][0]"
      ],
      "metadata": {
        "id": "nvNOkSshNS_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a Python list of all file names for each list\n",
        "train_file_list = list([item[0][0] for item in train_list[\"file_list\"]])\n",
        "test_file_list = list([item[0][0] for item in test_list[\"file_list\"]])\n",
        "full_file_list = list([item[0][0] for item in file_list[\"file_list\"]])\n",
        "\n",
        "len(train_file_list), len(test_file_list), len(full_file_list)"
      ],
      "metadata": {
        "id": "eJeb59hwNhfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some random samples\n",
        "import random\n",
        "\n",
        "random.sample(train_file_list, k=10)"
      ],
      "metadata": {
        "id": "aXkS0wOtN-kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that the training set and the test set doesn't have common items"
      ],
      "metadata": {
        "id": "tHWKdn36RFqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many files in the training set intersect with the testing set?\n",
        "len(set(train_file_list).intersection(test_file_list))"
      ],
      "metadata": {
        "id": "4n4VU746RCNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f04646-16f3-4a74-8956-5a0faf541547"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the Annotation folder"
      ],
      "metadata": {
        "id": "uKTF4C_F_kAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir(f\"{local_dir}/Annotation\")[:10]"
      ],
      "metadata": {
        "id": "QtFhompu_oNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are directories with dog breed names with several numbered files inside.\n",
        "Each of the numbered files contains a HTML version.\n",
        "For example, `Annotation/n02085620-Chihuahua/n02085620_10074`:\n",
        "\n",
        "```\n",
        "<annotation>\n",
        "\t<folder>02085620</folder>\n",
        "\t<filename>n02085620_10074</filename>\n",
        "\t<source>\n",
        "\t\t<database>ImageNet database</database>\n",
        "\t</source>\n",
        "\t<size>\n",
        "\t\t<width>333</width>\n",
        "\t\t<height>500</height>\n",
        "\t\t<depth>3</depth>\n",
        "\t</size>\n",
        "\t<segment>0</segment>\n",
        "\t<object>\n",
        "\t\t<name>Chihuahua</name>\n",
        "\t\t<pose>Unspecified</pose>\n",
        "\t\t<truncated>0</truncated>\n",
        "\t\t<difficult>0</difficult>\n",
        "\t\t<bndbox>\n",
        "\t\t\t<xmin>25</xmin>\n",
        "\t\t\t<ymin>10</ymin>\n",
        "\t\t\t<xmax>276</xmax>\n",
        "\t\t\t<ymax>498</ymax>\n",
        "\t\t</bndbox>\n",
        "\t</object>\n",
        "</annotation>\n",
        "```\n",
        "\n",
        "The fields include the name and the size of the image, the label of the object, and where it is insid ethe image (bounding box)."
      ],
      "metadata": {
        "id": "nsMEjIOMBeIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function to check the number of subfolders inside the `Annotation` folder (there should be 120 subfolder, one for each dog breed)."
      ],
      "metadata": {
        "id": "Z0thxTFsFt5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def count_subfolders(path: str) -> int:\n",
        "  \"\"\"\n",
        "    Count the number of subfolders in a given directory.\n",
        "\n",
        "    Args:\n",
        "    path (str): The path to the directory in which to count subfolders.\n",
        "\n",
        "    Returns:\n",
        "    int: The number of subfolders in the specified directory.\n",
        "\n",
        "    Examples:\n",
        "    >>> count_subfolders('/path/to/directory')\n",
        "    3  # if there are 3 subfolders in the specified directory\n",
        "  \"\"\"\n",
        "  return len([item for item in Path(path).iterdir() if item.is_dir()])\n",
        "\n",
        "annotation_path = f\"{local_dir}/Annotation\"\n",
        "folder_count = count_subfolders(annotation_path)\n",
        "print(f\"Number of subfolders in {annotation_path}: {folder_count}\")"
      ],
      "metadata": {
        "id": "yAddT9NZGOCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 120 subfolder of annotations, one for each class of dog.\n",
        "\n",
        "But it looks like the class names are already in the filepaths."
      ],
      "metadata": {
        "id": "tBdXy3JTH1qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View a single training file pathname\n",
        "train_file_list[0]"
      ],
      "metadata": {
        "id": "vtXeZ3ygIJ-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we know, that image `n02085620_5927.jpg` should contain a `Chihuahua`.\n",
        "Let's check."
      ],
      "metadata": {
        "id": "8uf0Y7bQIZYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(Path(f\"{local_dir}/Images/\", train_file_list[0]))"
      ],
      "metadata": {
        "id": "qlbcZMcaItBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the Images folder\n",
        "\n",
        "We know that the image file names come in the format `class_name/image_name`, for example, `n02085620-Chihuahua/n02085620_5927.jpg`.\n",
        "\n",
        "To make things a little simpler, let's create the following:\n",
        "\n",
        "1. A mapping from folder name -> class name in dictionary form, for example, `{'n02113712-miniature_poodle': 'miniature_poodle',  'n02092339-Weimaraner': 'weimaraner',  'n02093991-Irish_terrier': 'irish_terrier'...}`. This will help us when visualizing our data from its original folder.\n",
        "2. A list of all unique dog class names with simple formatting, for example, `['affenpinscher',  'afghan_hound',  'african_hunting_dog',  'airedale',  'american_staffordshire_terrier'...]`.\n"
      ],
      "metadata": {
        "id": "sp5j3TwiJG27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all image folders\n",
        "image_folders = os.listdir(f\"{local_dir}/Images\")\n",
        "image_folders[:10]"
      ],
      "metadata": {
        "id": "lkp3UglBKPor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a foldername -> class name dictionary\n",
        "folder_to_class_dictionary = {}\n",
        "for folder_name in image_folders:\n",
        "  class_name = folder_name.split(\"-\")[1].lower().replace(\"_\", \" \")\n",
        "  folder_to_class_dictionary[folder_name] = class_name\n",
        "\n",
        "# Make sure there are 120 entries in the dictionary\n",
        "assert len(folder_to_class_dictionary) == 120"
      ],
      "metadata": {
        "id": "oAyn-inWKmRm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(folder_to_class_dictionary.items())[:10]"
      ],
      "metadata": {
        "id": "Sgto11W6LQR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of unique dog names\n",
        "dog_names = sorted(list(set(folder_to_class_dictionary.values())))\n",
        "dog_names[:10]"
      ],
      "metadata": {
        "id": "riHYTYLPLjdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got:\n",
        "- a mapping from a folder name to a class name: `folder_to_class_dictionary`\n",
        "- a list of unique dog breeds: `dog_names`"
      ],
      "metadata": {
        "id": "T99UjGd-L3Yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize a group of random images\n",
        "\n",
        "Create a function that takes a list of image paths and randomly selects 10 paths to display.\n",
        "The function will:\n",
        "1. Take a list of image paths as input.\n",
        "2. Creat a grid of Matplotlib plots (e.g. 2x5)\n",
        "3. Using `random.sample()`, selects 10 image paths from the input list.\n",
        "4. Iterate through the flattened axes via `axes.flat` which is a reference to the attribute `numpy.ndarray.flat`.\n",
        "5. Extract the sample path from the list of samples.\n",
        "6. Get the sample title from the parent folder of the path using `Path.parent.stem` and then extract the formatted dog breed name by indexing `folder_to_class_name_dict`.\n",
        "7. Read the image with `plt.imread()` and show it on the target ax with `ax.imshow()`.\n",
        "8. Set the title of the plot to the parent folder name with `ax.set_title()` and turn the axis marks of with `ax.axis(\"off\")` (this makes for pretty plots).\n",
        "9. Show the plot with `plt.show()`."
      ],
      "metadata": {
        "id": "tb5kV9IqMtJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_10_random_images(image_paths: List[Path], extract_title: bool = True) -> None:\n",
        "  \"\"\"\n",
        "    Plots 10 random images from a list of image paths.\n",
        "\n",
        "    Args:\n",
        "    image_paths (List[Path]): A list of image paths to plot.\n",
        "    extract_title (bool): Whether to extract the title from the image path\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  # Setup a grid of plots\n",
        "  fig, axes = plt.subplots(ncols=5, nrows=2, figsize=(20, 10))\n",
        "\n",
        "  # Get a list of random image paths\n",
        "  samples = random.sample(image_paths, k=10)\n",
        "\n",
        "  # Iterate through the flattened axes and corresponding image paths\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "    # Get the image path\n",
        "    image_path = samples[i]\n",
        "    # Extract the parent directory name to use as the title (if neccesary)\n",
        "    if extract_title:\n",
        "      title = folder_to_class_dictionary[image_path.parent.stem]\n",
        "    else:\n",
        "      title = image_path.parent.stem\n",
        "\n",
        "    # Read the image\n",
        "    ax.imshow(plt.imread(image_path))\n",
        "    # Set the title\n",
        "    ax.set_title(title)\n",
        "    # Turn the axis off\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "plot_10_random_images(image_paths=[Path(f\"{local_dir}/Images/\") / path for path in train_file_list])\n"
      ],
      "metadata": {
        "id": "OA9A-nBbOTU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the distribution of the data\n",
        "\n",
        "How many images of dog we have per breed?\n",
        "\n",
        "A balanced distribution would mean, we have roughly the same number of images of every breed (e.g. 100 images per breed)\n",
        "\n",
        "Let's see, how many images we have per breed? Write e function, that counts the images in a given directory:\n",
        "\n",
        "1. Take in a target directory/folder.\n",
        "2. Create a list of all the subdirectories/subfolders in the target folder.\n",
        "3. Create an empty list, `image_class_counts` to append subfolders and their counts to.\n",
        "4. Iterate through all of the subdirectories.\n",
        "5. Get the class name of the target folder as the name of the folder.\n",
        "6. Count the number of images in the target folder using the length of the list of image paths (we can get these with `Path().rglob(*.jpg)` where `*.jpg` means \"all files with the extension `.jpg`\".\n",
        "7. Append a dictionary of `{\"class_name\": class_name, \"image_count\": image_count}` to the `image_class_counts` list (we create a list of dictionaries so we can turn this into a pandas DataFrame).\n",
        "8. Return the `image_class_counts` list."
      ],
      "metadata": {
        "id": "r_-3lxWJSn1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of image counts\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "\n",
        "def count_images_in_subfolders(target_dir: str) -> List[Dict[str, int]]:\n",
        "  \"\"\"\n",
        "    Counts the number of JPEG images in each subfolder in a given directory.\n",
        "    Each subdirectory is assumed to represent a class, and the function counts\n",
        "    the number of '.jpg' files within each one. The result is a list of\n",
        "    dictionaries with the class name and corresponding image count.\n",
        "\n",
        "    Args:\n",
        "    target_dir (str): The path to the directory in which to count\n",
        "\n",
        "    Returns:\n",
        "    List[Dict[str, int]]: A list of dictionaries with 'class_name' and 'image_count' for each subdirectory.\n",
        "\n",
        "    Examples:\n",
        "        >>> count_images_in_subdirs('/path/to/directory')\n",
        "        [{'class_name': 'beagle', 'image_count': 50}, {'class_name': 'poodle', 'image_count': 60}]\n",
        "  \"\"\"\n",
        "  # Create a list of all the subfolders in the target directory\n",
        "  image_dir = Path(target_dir)\n",
        "  subfolders = [folder for folder in image_dir.iterdir() if folder.is_dir()]\n",
        "\n",
        "  # Create an empty list to append image counts\n",
        "  image_class_counts = []\n",
        "\n",
        "  # Iterate through all of the subfolders\n",
        "  for subfolder in subfolders:\n",
        "    # Get the class name of the target folder as the name of the folder\n",
        "    class_name = subfolder.name\n",
        "\n",
        "    # Count the number of images in the target folder\n",
        "    image_count = len(list(subfolder.rglob(\"*.jpg\")))\n",
        "\n",
        "    # Append a dictionary of class name and image count to count list\n",
        "    image_class_counts.append({\"class_name\": class_name, \"image_count\": image_count})\n",
        "\n",
        "  # Return the count list\n",
        "  return image_class_counts\n"
      ],
      "metadata": {
        "id": "YHX7QyGjU_p3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the function on the target directory and view the first few indexes"
      ],
      "metadata": {
        "id": "pPpSJ1DWW5qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_class_counts = count_images_in_subfolders(f\"{local_dir}/Images\")\n",
        "image_class_counts[:10]"
      ],
      "metadata": {
        "id": "NrKbvvCUXDGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turn the `image_class_count` variable to a pandas `DataFrame`.\n",
        "\n",
        "Sort the `DataFrame` by `image_count`."
      ],
      "metadata": {
        "id": "0ZXcS99mXRo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "image_counts_dataframe = pd.DataFrame(image_class_counts).sort_values(\"image_count\", ascending=False)\n",
        "image_counts_dataframe.head()"
      ],
      "metadata": {
        "id": "1W49SOEjXqKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map the `class_name` column to the `folder_to_class_dictionary` to easier read."
      ],
      "metadata": {
        "id": "h-xF_ev3YJ_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_counts_dataframe[\"class_name\"] = image_counts_dataframe[\"class_name\"].map(folder_to_class_dictionary)\n",
        "image_counts_dataframe.head()"
      ],
      "metadata": {
        "id": "NLiMgXnuYiAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the distribution of the data by turning the DataFrame into a plot."
      ],
      "metadata": {
        "id": "IbGEZAt_YwD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "image_counts_dataframe.plot(kind=\"bar\",\n",
        "                            x=\"class_name\",\n",
        "                            y=\"image_count\",\n",
        "                            legend=False,\n",
        "                            ax=plt.gca())\n",
        "plt.title(\"Images per Dog Breed\")\n",
        "plt.xlabel(\"Dog Breed\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xticks(rotation=90, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZoPWS3bNZCFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some statistics about the DataFrame\n",
        "image_counts_dataframe.describe()"
      ],
      "metadata": {
        "id": "n4gVSAuIaR0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating training and test data split directories"
      ],
      "metadata": {
        "id": "MP_UMK2w94hF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After exploring the data, we need to create a training and test data splits. The original dataset already comes with this split, so we stick with these. But we also creating a smaller training set (about 10% of the original training set) for faster experimentation."
      ],
      "metadata": {
        "id": "g5unE1jS-hY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create:\n",
        "\n",
        "- a folder for training images `dog_vision_data/images/train`\n",
        "- a folder for test images `dog_vision_data/images/test`\n",
        "- inside each directory, make directories for each dog breed"
      ],
      "metadata": {
        "id": "Q3YQH4W9_bzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Target directory for image splits\n",
        "image_split_directory = Path(local_dir, \"images_split\")\n",
        "\n",
        "# Training and test directories\n",
        "train_dir = image_split_directory / \"train\"\n",
        "test_dir = image_split_directory / \"test\"\n",
        "\n",
        "# Create the target directories if it doesn't exist\n",
        "train_dir.mkdir(parents=True, exist_ok=True)\n",
        "test_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Directory {train_dir} is exists.\")\n",
        "print(f\"Directory {test_dir} is exists.\")\n",
        "\n",
        "# Make folders for each dog breeds\n",
        "for dog_name in dog_names:\n",
        "  # Make training folder\n",
        "  dog_train_dir = train_dir / dog_name\n",
        "  dog_train_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Make test folder\n",
        "  dog_test_dir = test_dir / dog_name\n",
        "  dog_test_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Check if 120 subfolder in each folder\n",
        "assert count_subfolders(train_dir) == len(dog_names)\n",
        "assert count_subfolders(test_dir) == len(dog_names)"
      ],
      "metadata": {
        "id": "dz4xvB0ZBUgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the first 10 directories in the training directory\n",
        "sorted([str(dir_name) for dir_name in train_dir.iterdir() if dir_name.is_dir()])[:10]"
      ],
      "metadata": {
        "id": "lgUDeVTVEhXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function which will copy images from the `Images` folder into the respective directories inside `images_split/train` and `images_split/test`\n",
        "\n",
        "Specifically:\n",
        "\n",
        "1. Take in a list of source files to copy (e.g. `train_file_list`) and a target directory to copy files to.\n",
        "2. Iterate through the list of sources files to copy (use `tqdm` which comes installed with Google Colab to create a progress bar of how many files have been copied).\n",
        "3. Convert the source file path to a `Path` object.\n",
        "4. Split the source file path and create a `Path` object for the destination folder (e.g. \"n02112018-Pomeranian\" -> \"pomeranian\").\n",
        "5. Get the target file name (e.g. \"n02112018-Pomeranian/n02112018_6208.jpg\" -> \"n02112018_6208.jpg\").\n",
        "6. Create a destination path for the source file to be copied to (e.g. `images_split/train/pomeranian/n02112018_6208.jpg`).\n",
        "7. Ensure the destination directory exists, similar to the step we took in the previous section (you can't copy files to a directory that doesn't exist).\n",
        "8. Print out the progress of copying (if necessary).\n",
        "9. Copy the source file to the destination using Python's `shutil.copy2(src, dst)`."
      ],
      "metadata": {
        "id": "9j7dAHCNFKIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from shutil import copy2\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def copy_files_to_target_directory(file_list: List[str],\n",
        "                                   target_dir: str,\n",
        "                                   images_dir: str = \"dog_vision_data/Images\",\n",
        "                                   verbose: bool = False) -> None:\n",
        "  \"\"\"\n",
        "  Copies a list of files from the images directory to a target directory.\n",
        "\n",
        "  Parameters:\n",
        "  file_list (list[str]): A list of file paths to copy.\n",
        "  target_dir (str): The destination directory path where files will be copied.\n",
        "  images_dir (str, optional): The directory path where the images are currently stored. Defaults to 'dog_vision_data/Images'.\n",
        "  verbose (bool, optional): If set to True, the function will print out the file paths as they are being copied. Defaults to False.\n",
        "\n",
        "  Returns:\n",
        "  None\n",
        "  \"\"\"\n",
        "  # Iterate through source files\n",
        "  for file in tqdm(file_list):\n",
        "    # Convert file path to Path object\n",
        "    source_file_path = Path(images_dir) / Path(file)\n",
        "\n",
        "    # Split the file path and create a Path object for destination folder\n",
        "    file_class_name = folder_to_class_dictionary[Path(file).parts[0]]\n",
        "\n",
        "    # Get the name of the image\n",
        "    file_image_name = Path(file).name\n",
        "\n",
        "    # Create destination path\n",
        "    destination_path = Path(target_dir) / file_class_name / file_image_name\n",
        "\n",
        "    # Check if destination directory exists\n",
        "    destination_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Print out copy message, if neccesary\n",
        "    if verbose:\n",
        "      print(f\"[INFO] Copying: {source_file_path} to {destination_path}\")\n",
        "\n",
        "    # Copy the file to the destination\n",
        "    copy2(source_file_path, destination_path)"
      ],
      "metadata": {
        "id": "0uX2bq4YGppZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the copy function by copying files from `train_file_list` to `train_dir`"
      ],
      "metadata": {
        "id": "7ZiTbbCOJdut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files_to_target_directory(file_list=train_file_list,\n",
        "                               target_dir=train_dir,\n",
        "                               verbose=False)"
      ],
      "metadata": {
        "id": "zyJjptX0JZ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy files from `test_file_list` to `test_dir`"
      ],
      "metadata": {
        "id": "-BUudrl9KLce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files_to_target_directory(file_list=test_file_list,\n",
        "                               target_dir=test_dir,\n",
        "                               verbose=False)"
      ],
      "metadata": {
        "id": "m7ulL-KHKSXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the number of files in the `train_file_list` is the same as the number of images in the `train_dir` (and also check the test files)."
      ],
      "metadata": {
        "id": "oNMemZSTKfN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all .jpg file paths in train and test image folders\n",
        "train_image_paths = list(train_dir.rglob(\"*.jpg\"))\n",
        "test_image_paths = list(test_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "# Make sure the number of images in the train and test directories equals the number of files in the original lists\n",
        "assert len(train_image_paths) == len(train_file_list)\n",
        "assert len(test_image_paths) == len(test_file_list)\n",
        "\n",
        "print(f\"Number of images in {train_dir}: {len(train_image_paths)}\")\n",
        "print(f\"Number of images in {test_dir}: {len(test_image_paths)}\")"
      ],
      "metadata": {
        "id": "_m6oCyALK8WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot some random images from the `train_image_path`"
      ],
      "metadata": {
        "id": "2n0xwSbAMMa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_10_random_images(image_paths=train_image_paths,\n",
        "                      extract_title=False)"
      ],
      "metadata": {
        "id": "E7EW0YhfMWKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a 10% training dataset split"
      ],
      "metadata": {
        "id": "ZDZDsCiRM-Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make model experiments faster, we create a smaller (~10%) training dataset in the `images_split` directory.\n",
        "To make this dataset, we copy a random 10% of the existing training set to a new folder, named `images_split/train_10_percent`."
      ],
      "metadata": {
        "id": "aLnTROs0NSrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 10% folder\n",
        "train_10_percent_dir = image_split_directory / \"train_10_percent\"\n",
        "train_10_percent_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "PrE-Y7hfOEmk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(image_split_directory)"
      ],
      "metadata": {
        "id": "7RXtZA43OPW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4526b775-8390-403d-934e-6dd1f1148bab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_10_percent', 'test', 'train']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take 10% random sample from the train_image_paths\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "train_image_paths_10_percent = random.sample(population=train_image_paths,\n",
        "                                             k=int(len(train_image_paths) * 0.1))\n",
        "\n",
        "print(f\"Original number of images: {len(train_image_paths)}\")\n",
        "print(f\"Number of images in 10% sample: {len(train_image_paths_10_percent)}\")\n",
        "print(\"First 5 random images in 10% sample:\")\n",
        "train_image_paths_10_percent[:5]"
      ],
      "metadata": {
        "id": "tBb6moktPdID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the 10% random sample to the sample directory"
      ],
      "metadata": {
        "id": "vK-9PK49QPyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for source_file_path in tqdm(train_image_paths_10_percent):\n",
        "  # Create the destination file path\n",
        "  destination_file_and_image_name = Path(*source_file_path.parts[-2:])\n",
        "  destination_path = train_10_percent_dir / destination_file_and_image_name\n",
        "\n",
        "  # Create the target directory if not exists\n",
        "  target_class_dir = destination_path.parent\n",
        "  if not target_class_dir.is_dir():\n",
        "    target_class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Copy the file to the destination\n",
        "  copy2(source_file_path, destination_path)"
      ],
      "metadata": {
        "id": "Wc9Jv6rPQX4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the 10% set distribution and make sure we've got some images for each class."
      ],
      "metadata": {
        "id": "5b3W93nIRbqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count images in the 10% directory\n",
        "train_10_percent_image_class_count  = count_images_in_subfolders(train_10_percent_dir)\n",
        "train_10_percent_image_class_count_df = pd.DataFrame(train_10_percent_image_class_count).sort_values(\"image_count\", ascending=True)\n",
        "train_10_percent_image_class_count_df.head()"
      ],
      "metadata": {
        "id": "3PDBWJ7RRtzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many subfolders are in the 10% directory\n",
        "print(len(train_10_percent_image_class_count_df))"
      ],
      "metadata": {
        "id": "gizQkhiYSPNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b25a4aa-0760-46ea-b394-13277de3e6e6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the distribution of the 10% training set"
      ],
      "metadata": {
        "id": "Uj1-sEbtSciC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "train_10_percent_image_class_count_df.plot(kind=\"bar\",\n",
        "                                           x=\"class_name\",\n",
        "                                           y=\"image_count\",\n",
        "                                           legend=False,\n",
        "                                           ax=plt.gca())\n",
        "\n",
        "plt.title(\"Images per Dog Breed (10% Sample)\")\n",
        "plt.xlabel(\"Dog Breed\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xticks(rotation=90, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#"
      ],
      "metadata": {
        "id": "Vx1YIqJSSikn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turning datasets into TensorFlow dataset(s)"
      ],
      "metadata": {
        "id": "zsgBEgxhVrzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert the images to tensors to train the ML model.\n",
        "The reason why we sort the images to the classic image classification format (where the class name is the directory name) is, because TensorFlow offers some utility functions to load data from this format.\n",
        "\n",
        "| Function |\tDescription |\n",
        "|-----------------------------------|-----------------------------------|\n",
        "| tf.keras.utils.image_dataset_from_directory() |\tCreates a tf.data.Dataset from image files in a directory. |\n",
        "| tf.keras.utils.audio_dataset_from_directory() |\tCreates a tf.data.Dataset from audio files in a directory. |\n",
        "| tf.keras.utils.text_dataset_from_directory() |\tCreates a tf.data.Dataset from text files in a directory. |\n",
        "| tf.keras.utils.timeseries_dataset_from_array() |\tCreates a dataset of sliding windows over a timeseries provided as array. |\n",
        "\n",
        "We'll use the `tf.keras.utils.image_dataset_from_directory()` with the following parameters:\n",
        "\n",
        "- `directory` = the target directory we'd like to turn into a `tf.data.Dataset`.\n",
        "- `label_mode` = the kind of labels we'd like to use, in our case it's `\"categorical\"` since we're dealing with a multi-class classification problem (we would use `\"binary\"` if we were working with binary classifcation problem).\n",
        "- `batch_size` = the number of images we'd like our model to see at a time (due to computation limitations, our model won't be able to look at every image at once so we split them into small batches and the model looks at each batch individually), generally 32 is a good value to start, this means our model will look at 32 images at a time (this number is flexible).\n",
        "- `image_size` = the size we'd like to shape our images to before we feed them to our model (height x width).\n",
        "- `shuffle` = whether we'd like our dataset to be shuffled to randomize the order.\n",
        "- `seed` = if we're shuffling the order in a random fashion, do we want that to be reproducible?"
      ],
      "metadata": {
        "id": "WWs_iQtvVydN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make 3 `tf.data.Dataset` for `train`, `test` and `10%_train` datasets."
      ],
      "metadata": {
        "id": "DSsZPYRRZUdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create some constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "\n",
        "# Create 10% train dataset\n",
        "train_10_percent_ds = tf.keras.utils.image_dataset_from_directory(directory=train_10_percent_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  batch_size=BATCH_SIZE,\n",
        "                                                                  image_size=IMG_SIZE,\n",
        "                                                                  shuffle=True,\n",
        "                                                                  seed=SEED)\n",
        "\n",
        "# Create full train dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(directory=train_dir,\n",
        "                                                       label_mode=\"categorical\",\n",
        "                                                       batch_size=BATCH_SIZE,\n",
        "                                                       image_size=IMG_SIZE,\n",
        "                                                       shuffle=True,\n",
        "                                                       seed=SEED)\n",
        "\n",
        "# Create test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(directory=test_dir,\n",
        "                                                      label_mode=\"categorical\",\n",
        "                                                      batch_size=BATCH_SIZE,\n",
        "                                                      image_size=IMG_SIZE,\n",
        "                                                      shuffle=False,\n",
        "                                                      seed=SEED)\n"
      ],
      "metadata": {
        "id": "JPpsoWYQZrZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the 10% dataset\n",
        "train_10_percent_ds"
      ],
      "metadata": {
        "id": "s72zLNbObC1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check a single batch in a dataset\n",
        "image_batch, label_batch = next(iter(train_ds))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "id": "cYgsOuD1bWlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single sample from a batch\n",
        "print(f\"Single image tensor:\\n {image_batch[0]}\\n\")\n",
        "print(f\"Single label tensor:\\n {label_batch[0]}\")\n",
        "print(f\"Single sample class name: {dog_names[tf.argmax(label_batch[0])]}\")\n"
      ],
      "metadata": {
        "id": "vWfu29bWbuRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualizing images from TensorFlow Dataset"
      ],
      "metadata": {
        "id": "JucoTl85ccrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a single image\n",
        "plt.imshow(image_batch[0].numpy().astype(\"uint8\"))\n",
        "plt.title(dog_names[tf.argmax(label_batch[0])])\n",
        "plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "JDOu9D5RcoS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot multiple images\n",
        "\n",
        "# Create multiple subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 10))\n",
        "\n",
        "# Iterate through a single batch and plot images\n",
        "for images, labels in train_ds.take(count=1):\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    ax.set_title(dog_names[tf.argmax(labels[i])])\n",
        "    ax.axis(\"off\")"
      ],
      "metadata": {
        "id": "Z0bV8XOadCjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Getting labels from TensorFlow Datasets"
      ],
      "metadata": {
        "id": "cRQ9Hwq9d28Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first 5 file paths from the training dataset\n",
        "train_ds.file_paths[:5]"
      ],
      "metadata": {
        "id": "OjAVJmKXeI6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names\n",
        "class_names = train_ds.class_names\n",
        "class_names[:5]"
      ],
      "metadata": {
        "id": "KpM1XFQ0eWWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the class names are the same in each dataset\n",
        "assert set(train_10_percent_ds.class_names) == set(train_ds.class_names) == set(test_ds.class_names)"
      ],
      "metadata": {
        "id": "X7syMeAMejmp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuring the datasets for performance\n",
        "\n",
        "We're going to call three methods on our dataset to optimize it for performance:\n",
        "\n",
        "- `cache()` - Cache the elements in the dataset in memory or a target folder (speeds up loading).\n",
        "- `shuffle()` - Shuffle a set number of samples in preparation for loading (this will mean our samples and batches of samples will be shuffled), for example, setting `shuffle(buffer_size=1000)` will prepare and shuffle 1000 elements of data at a time.\n",
        "- `prefetch()` - Prefetch the next batch of data and prepare it for computation whilst the previous one is being computed on (can scale to multiple prefetches depending on hardware availability). TensorFlow can automatically configure how many elements/batches to prefetch by setting `prefetch(buffer_size=tf.data.AUTOTUNE)`."
      ],
      "metadata": {
        "id": "aKPOURSfezLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Shuffle and optimize performance on training datasets\n",
        "train_10_percent_ds = train_10_percent_ds.cache().shuffle(buffer_size=10*BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "train_ds = train_ds.cache().shuffle(buffer_size=100*BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Don't shuffle the test dataset\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "sLn6STIoffHI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a neural network with TensorFlow"
      ],
      "metadata": {
        "id": "H9vOhd_AiPzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a base model"
      ],
      "metadata": {
        "id": "SzjEdSmmsuUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of building a neural network from scratch, we'll use transfer learning. We're going to use a pretraned model from `tf.keras.applications`, specifically the `tf.keras.applications.effcientnet_v2.EfficientNetV2B0()` model."
      ],
      "metadata": {
        "id": "jMadQdPWiUDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create an instance of the model and calll it `base_model`."
      ],
      "metadata": {
        "id": "KhSEawk_jBJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the input shape to our model\n",
        "INPUT_SHAPE = (*IMG_SIZE, 3)\n",
        "\n",
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=True,\n",
        "    include_preprocessing=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=INPUT_SHAPE\n",
        ")\n"
      ],
      "metadata": {
        "id": "vrTEvXMfjLau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Information about the base_model\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "YgBKH87Kj-N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of layers\n",
        "print(f\"Number of layers in the base model: {len(base_model.layers)}\")"
      ],
      "metadata": {
        "id": "0cZhlG81kRqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the used model has 1000 output classes and we want classify 120 different dog breeds, we need to change the model configuration. We want to use our own output layer."
      ],
      "metadata": {
        "id": "-jiiK7xnlCLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=False,\n",
        "    include_preprocessing=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=INPUT_SHAPE\n",
        ")"
      ],
      "metadata": {
        "id": "avsTwpxAlaYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of parameters the model has\n",
        "base_model.count_params()"
      ],
      "metadata": {
        "id": "K3rKHA9ymBti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcc3461-cc48-4984-ec7e-3148e78e6a5b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5919312"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write e function that count the trainable and non-trainable parameters of a model."
      ],
      "metadata": {
        "id": "8dXI9e9nmTnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def count_parameters(model, print_output=True):\n",
        "  \"\"\"\n",
        "  Counts the number of trainable, non-trainable and total parameters of a given model.\n",
        "  \"\"\"\n",
        "  trainable_parameters = np.sum([np.prod(layer.shape) for layer in model.trainable_weights])\n",
        "  non_trainable_parameters = np.sum([np.prod(layer.shape) for layer in model.non_trainable_weights])\n",
        "  total_parameters = trainable_parameters + non_trainable_parameters\n",
        "  if print_output:\n",
        "    print(f\"Model {model.name} parameter counts:\")\n",
        "    print(f\"Total parameters: {total_parameters}\")\n",
        "    print(f\"Trainable parameters: {trainable_parameters}\")\n",
        "    print(f\"Non-trainable parameters: {non_trainable_parameters}\")\n",
        "  else:\n",
        "    return total_parameters, trainable_parameters, non_trainable_parameters\n",
        "\n",
        "count_parameters(base_model)\n"
      ],
      "metadata": {
        "id": "UtguXdz3mbmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has more than 5 million trainable parameter. To speed up the learning process, we'll *freeze* the layers of the base model and only train the custom top layers to suit our problem."
      ],
      "metadata": {
        "id": "xRltnlzBnS0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "base_model.trainable\n",
        "count_parameters(base_model)"
      ],
      "metadata": {
        "id": "Ezzb7Iv-n3hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to reshape our data to match the input shape of the model.\n",
        "\n",
        "The shape of our data: `(224, 224, 3) (height, width, color channels)`\n",
        "\n",
        "The expected input shape of the model: `(None, 224, 224, 3) (batch_size, height, width, color channels)`\n",
        "\n",
        "We need to add one dimension to our data."
      ],
      "metadata": {
        "id": "h8VNFcQiofXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Current image shape\n",
        "image_shape_without_batch = image_batch[0].shape\n",
        "\n",
        "# Add a batch dimension to our single image\n",
        "image_shape_with_batch = tf.expand_dims(input=image_batch[0], axis=0).shape\n",
        "\n",
        "print(f\"Single image shape without batch: {image_shape_without_batch}\")\n",
        "print(f\"Single image shape with batch: {image_shape_with_batch}\")"
      ],
      "metadata": {
        "id": "0TzbiDeVpWvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to extract features from a single image using the base_model\n",
        "feature_extraction = base_model(tf.expand_dims(image_batch[0], axis=0))\n",
        "feature_extraction"
      ],
      "metadata": {
        "id": "mKLfwV5sp_KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the feature extraction into a feature vector using Average pooling\n",
        "feature_vector = tf.keras.layers.GlobalAveragePooling2D()(feature_extraction)\n",
        "feature_vector"
      ],
      "metadata": {
        "id": "5DlTJcHArLV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's recreate the `base_model` but with a built-in pooling layer."
      ],
      "metadata": {
        "id": "4gCnnRcor_Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a base model with no top and a pooling layer built-in\n",
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    pooling=\"avg\", # can also use \"max\"\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "\n",
        "# Check the output shape\n",
        "base_model.output_shape"
      ],
      "metadata": {
        "id": "2pejJgP0sQsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53552cd0-66ae-470c-fa39-3261dc73d6d3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 1280)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Count the parameters\n",
        "count_parameters(base_model)"
      ],
      "metadata": {
        "id": "Nhsx1KtYsYC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a custom model for our problem (Dog Vison)\n",
        "\n",
        "The main steps when creating any kind of deep learning model from scratch are:\n",
        "\n",
        "1. Define the input layer(s).\n",
        "2. Define the middle layer(s).\n",
        "3. Define the output layer(s).\n",
        "\n",
        "Good news is, thanks to transfer learning, all of our middle layers are defined by `base_model`.\n",
        "\n",
        "So now it's up to us to define our input and output layers.\n",
        "\n",
        "TensorFlow/Keras have two main ways of connecting layers to form a model.\n",
        "\n",
        "1. The Sequential model `(tf.keras.Sequential)` - Useful for making simple models with one tensor in and one tensor out, not suited for complex models.\n",
        "2. The Functional API - Useful for making more complex and multi-step models but can also be used for simple models.\n",
        "\n",
        "Start with the Sequential model.\n",
        "\n",
        "It takes a list of layers and will pass data through them sequentially.\n",
        "\n",
        "Our `base_model` will be the input and middle layers and we'll use a `tf.keras.layers.Dense()` layer as the output."
      ],
      "metadata": {
        "id": "3YLfiWvGszJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a model with the Sequential API"
      ],
      "metadata": {
        "id": "j2aDJnMQt9gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequential model\n",
        "tf.random.set_seed(42)\n",
        "sequential_model = tf.keras.Sequential(\n",
        "    [\n",
        "        base_model, # Input and middle layers\n",
        "        tf.keras.layers.Dense(units=len(class_names),\n",
        "                              activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "sequential_model.summary()"
      ],
      "metadata": {
        "id": "Ij0c3dOLuD-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the input shape of the model\n",
        "sequential_model.input_shape"
      ],
      "metadata": {
        "id": "9QGYw9Y1u-pR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21fc0f0c-7d48-4ed6-8238-f153b2f66100"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the output shape of the model\n",
        "sequential_model.output_shape"
      ],
      "metadata": {
        "id": "QKSg5IbJvF2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b222d114-7e5e-419a-b331-4afe1756aae9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try out the model with one image\n",
        "single_image_input = tf.expand_dims(image_batch[0], axis=0)\n",
        "\n",
        "# Pass the image through the model\n",
        "single_image_output_sequential = sequential_model(single_image_input)\n",
        "\n",
        "# Check the output\n",
        "single_image_output_sequential"
      ],
      "metadata": {
        "id": "KP5v2HfavTXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum the output\n",
        "np.sum(single_image_output_sequential)"
      ],
      "metadata": {
        "id": "5IZnaZ6lvvjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the index with the highest value\n",
        "highest_value_index_sequential_model_output = np.argmax(single_image_output_sequential)\n",
        "highest_value_sequential_model_output = np.max(single_image_output_sequential)\n",
        "\n",
        "print(f\"Highest value index: {highest_value_index_sequential_model_output} ({dog_names[highest_value_index_sequential_model_output]})\")\n",
        "print(f\"Prediction probability: {highest_value_sequential_model_output}\")"
      ],
      "metadata": {
        "id": "gNjbcjhCwTBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the original label value of the picture\n",
        "print(f\"Predicted value: {highest_value_index_sequential_model_output}\")\n",
        "print(f\"Actual value: {tf.argmax(label_batch[0]).numpy()}\")"
      ],
      "metadata": {
        "id": "b_YCmbQXwjVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on class_names with our model's highest prediction probability\n",
        "sequential_model_predicted_label = class_names[tf.argmax(sequential_model(tf.expand_dims(image_batch[0], axis=0)), axis=1).numpy()[0]]\n",
        "\n",
        "# Get the truth label\n",
        "single_image_ground_truth_label = class_names[tf.argmax(label_batch[0])]\n",
        "\n",
        "# Print predicted and ground truth labels\n",
        "print(f\"Sequential model predicted label: {sequential_model_predicted_label}\")\n",
        "print(f\"Ground truth label: {single_image_ground_truth_label}\")"
      ],
      "metadata": {
        "id": "5-Dj0gmEwu5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a model with the Functional API"
      ],
      "metadata": {
        "id": "XU-7_AgqxLjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create input layer\n",
        "inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
        "\n",
        "# 2. Create hidden layer\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# 3. Create the output layer\n",
        "outputs = tf.keras.layers.Dense(units=len(class_names), # one output per class\n",
        "                                activation=\"softmax\",\n",
        "                                name=\"output_layer\")(x)\n",
        "\n",
        "# 4. Connect the inputs and outputs together\n",
        "functional_model = tf.keras.Model(inputs=inputs,\n",
        "                                  outputs=outputs,\n",
        "                                  name=\"functional_model\")\n",
        "\n",
        "# Get a model summary\n",
        "functional_model.summary()"
      ],
      "metadata": {
        "id": "6cYwM9nrxWWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try out the functional model"
      ],
      "metadata": {
        "id": "GyGmfICExlbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass a single image through our functional_model\n",
        "single_image_output_functional = functional_model(single_image_input)\n",
        "\n",
        "# Find the index with the highest value\n",
        "highest_value_index_functional_model_output = np.argmax(single_image_output_functional)\n",
        "highest_value_functional_model_output = np.max(single_image_output_functional)\n",
        "\n",
        "highest_value_index_functional_model_output, highest_value_functional_model_output"
      ],
      "metadata": {
        "id": "A14oDY_ZxoHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functionizing model creation"
      ],
      "metadata": {
        "id": "FuV7h_G5x4EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would be quite tedious to rewrite the model creation code every time we wanted to create a new model.\n",
        "\n",
        "Create a function to replicate the model creation steps with the Functional API"
      ],
      "metadata": {
        "id": "xG4VJh0uyBXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(include_top: bool = False,\n",
        "                 num_classes: int = 1000,\n",
        "                 input_shape: tuple[int, int, int] = (224, 224, 3),\n",
        "                 include_preprocessing: bool = True,\n",
        "                 trainable: bool = False,\n",
        "                 dropout: float = 0.2,\n",
        "                 model_name: str = \"model\") -> tf.keras.Model:\n",
        "  \"\"\"\n",
        "  Create an EfficientNetV2 B0 feature extractor model with a custom classifier layer.\n",
        "\n",
        "  Args:\n",
        "      include_top (bool, optional): Whether to include the top (classifier) layers of the model.\n",
        "      num_classes (int, optional): Number of output classes for the classifier layer.\n",
        "      input_shape (tuple[int, int, int], optional): Input shape for the model's images (height, width, channels).\n",
        "      include_preprocessing (bool, optional): Whether to include preprocessing layers for image normalization.\n",
        "      trainable (bool, optional): Whether to make the base model trainable.\n",
        "      dropout (float, optional): Dropout rate for the global average pooling layer.\n",
        "      model_name (str, optional): Name for the created model.\n",
        "\n",
        "  Returns:\n",
        "      tf.keras.Model: A TensorFlow Keras model with the specified configuration.\n",
        "  \"\"\"\n",
        "  # Create base model\n",
        "  base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=include_top,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=input_shape,\n",
        "    include_preprocessing=include_preprocessing,\n",
        "    pooling=\"avg\" # Can use this instead of adding tf.keras.layers.GlobalPooling2D() to the model\n",
        "    # pooling=\"max\" # Can use this instead of adding tf.keras.layers.MaxPooling2D() to the model\n",
        "  )\n",
        "\n",
        "  # Freeze the base model (if necessary)\n",
        "  base_model.trainable = trainable\n",
        "\n",
        "  # Create input layer\n",
        "  inputs = tf.keras.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "  # Create model backbone (middle/hidden layers)\n",
        "  x = base_model(inputs, training=trainable)\n",
        "  # x = tf.keras.layers.GlobalAveragePooling2D()(x) # note: you should include pooling here if not using `pooling=\"avg\"`\n",
        "  # x = tf.keras.layers.Dropout(0.2)(x) # optional regularization layer (search \"dropout\" for more)\n",
        "\n",
        "  # Create output layer (also known as \"classifier\" layer)\n",
        "  outputs = tf.keras.layers.Dense(units=num_classes,\n",
        "                                  activation=\"softmax\",\n",
        "                                  name=\"output_layer\")(x)\n",
        "\n",
        "  # Connect input and output layer\n",
        "  model = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=model_name)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "AfQ6NHPUyjOQ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try out the new function\n",
        "model_0 = create_model(num_classes=len(class_names))\n",
        "model_0.summary()"
      ],
      "metadata": {
        "id": "TRkpBQovzAQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which layers are trainable\n",
        "for layer in model_0.layers:\n",
        "  print(f\"{layer.name}: {layer.trainable}\")"
      ],
      "metadata": {
        "id": "wCBXOK4Tzhxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0 - Train a model on 10% of the training data"
      ],
      "metadata": {
        "id": "d9iSPO7Ze8k-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's predictions are not so well yet. The model essentially predicting random classes for a given picture. We need to train the model's final layer to make predictions more accurate.\n",
        "This can do in five steps:\n",
        "\n",
        "1. Creating a model - We've done this\n",
        "2. Compiling the model - Here we tell the model how to improve itself and how to measure its performance.\n",
        "3. Fitting the model - Here we'll show the model a bunch of images to learn.\n",
        "4. Evaluating the model - After training we can evaluate the model on testing data.\n",
        "5. Making custom prediction - After the evaluation, we'll test the model on custom images."
      ],
      "metadata": {
        "id": "wcGWrTeTfEmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model\n",
        "model_0 = create_model(num_classes=len(class_names),\n",
        "                       model_name=\"model_0\")\n",
        "model_0.summary()"
      ],
      "metadata": {
        "id": "5cLAvEzDg1Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling a model\n",
        "After we've created a model, the next step is to compile it.\n",
        "\n",
        "If creating a model is putting together learning blocks, compiling a model is to getting those learning blocks ready to learn.\n",
        "\n",
        "We can compile our model_0 using the tf.keras.Model.compile() method.\n",
        "\n",
        "There are many options we can pass to the compile() method, however, the main ones we'll be focused on are:\n",
        "\n",
        "- The optimizer - this tells the model how to improve based on the loss value.\n",
        "- The loss function - this measures how wrong the model is (e.g. how far off are its predictions from the truth, an ideal loss value is 0, meaning the model is perfectly predicting the data).\n",
        "- The metric(s) - this is a human-readable value that shows how your model is performing, for example, accuracy is often used as an evaluation metric.\n",
        "\n",
        "These three settings work together to help improve a model."
      ],
      "metadata": {
        "id": "u2-7OVUqhRor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create an optimizer"
      ],
      "metadata": {
        "id": "pFdCQhRCh1Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "optimizer"
      ],
      "metadata": {
        "id": "1ZZPm3Jhh5nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a loss function"
      ],
      "metadata": {
        "id": "lugkTEoEiDCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the labels are one-hot encoded\n",
        "label_batch[0]"
      ],
      "metadata": {
        "id": "255Ni14kiGzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the loss function\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False) # using from_logits=False because we'll use an activation function in the last layer\n",
        "loss"
      ],
      "metadata": {
        "id": "SgDpHPtdiSQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a metrics to measure the model's performance"
      ],
      "metadata": {
        "id": "jXNQLpuDi5KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a metrics\n",
        "metrics = [\"accuracy\"]# We're using a list, because the model's compile method expects a list"
      ],
      "metadata": {
        "id": "CWPist8bjI9_"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling the model"
      ],
      "metadata": {
        "id": "-NaFxnROjhUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_0.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=metrics)"
      ],
      "metadata": {
        "id": "CBFedk5ajtNz"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting the model on 10% training data\n",
        "\n",
        "We'll be train our model on the 10% dataset we've created earlier. To speed up the training, we'll train the model on 5 epochs."
      ],
      "metadata": {
        "id": "qZqjGjIQj8P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model_0 for 5 epochs\n",
        "epochs = 5\n",
        "history_0 = model_0.fit(x=train_10_percent_ds,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=test_ds)"
      ],
      "metadata": {
        "id": "blJQVL-kkiBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate Model 0 on the test data\n",
        "\n",
        "Evaluating a model is just as important as training a model.\n",
        "\n",
        "There are several ways to evaluate a model:\n",
        "\n",
        "- Look at the metrics (such as accuracy).\n",
        "- Plot the loss curves.\n",
        "- Make predictions on the test set and compare them to the truth labels.\n",
        "- Make predictions on custom samples (not contained in the training or test sets).\n",
        "\n",
        "We've done the first one, as these metrics were the outputs of our model training.\n",
        "\n",
        "Now we're going to focus on the next two.\n",
        "\n",
        "Plotting loss curves and making predictions on the test set.\n",
        "\n",
        "So what are loss curves?\n",
        "\n",
        "Loss curves are a visualization of how your model's loss value performs overtime.\n",
        "\n",
        "We say loss \"curves\" because you can have a loss curve for each dataset, training, validation and test.\n",
        "\n",
        "An ideal loss curve will start high and move towards zero (a perfect model will have a loss value of zero).\n",
        "\n",
        "How do we get a loss curve?\n",
        "\n",
        "We could manually plot the loss values output from our model training.\n",
        "\n",
        "Or we could programmatically get the values thanks to the `History` object.\n",
        "\n",
        "This object is returned by the `fit` method of `tf.keras.Model` instances.\n",
        "\n",
        "And we've already got one!\n",
        "\n",
        "It's saved to `history_0` (the model history for `model_0`)."
      ],
      "metadata": {
        "id": "payBjspPldrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the history of model_0\n",
        "history_0.history"
      ],
      "metadata": {
        "id": "sPzGBPrbmWqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function to plot the loss and accuracy curves of a history object"
      ],
      "metadata": {
        "id": "RXNhEo-xmkKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_loss_curves(history: tf.keras.callbacks.History) -> None:\n",
        "  \"\"\"Takes a History object and plots loss and accuracy curves.\"\"\"\n",
        "\n",
        "  # Get the accuracy values\n",
        "  acc = history.history[\"accuracy\"]\n",
        "  val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "  # Get the loss values\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  # Get the number of epochs\n",
        "  epochs_range = range(len(acc))\n",
        "\n",
        "  # Create accuracy curves plot\n",
        "  plt.figure(figsize=(14, 7))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
        "  plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.title(\"Training and Validation Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "\n",
        "  # Create loss curves plot\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
        "  plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.title(\"Training and Validation Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_model_loss_curves(history=history_0)"
      ],
      "metadata": {
        "id": "a_Ux-FEjmyxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ideally, the training and test loss curves closely follow eeach other. In this case, the validation loss doesn't decrease as low as the training loss. This means our model is overfitting (not generailze enough on the training data).\n",
        "\n",
        "There are many way to fix overfitting (the best way is to use more data).\n",
        "\n",
        "But before we use more training data, let's evaluate the model."
      ],
      "metadata": {
        "id": "tjhGPqugnWvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results = model_0.evaluate(x=test_ds)"
      ],
      "metadata": {
        "id": "GsxQHzEpoRAJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
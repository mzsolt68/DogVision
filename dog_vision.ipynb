{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uzvP409-BkDkfGOrePIsP57TDqw_57Kb",
      "authorship_tag": "ABX9TyN9rTlE1bZ9i1dQTCickLgq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzsolt68/DogVision/blob/main/dog_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-end Multi-class Dog Breed Classification (v2)\n",
        "\n",
        "Building an end-to-end multi-class image classifier using TensorFlow\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Identifying the breed of a dog from a given image\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "We're going to use the Stanford Dogs dataset, which is available from several sources:\n",
        "* The original project website: http://vision.stanford.edu/aditya86/ImageNetDogs/\n",
        "* Inside the Tensorflow datasets: https://www.tensorflow.org/datasets/catalog/stanford_dogs\n",
        "* On Kaggle: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
        "\n",
        "## 3. Using the data\n",
        "\n",
        "To make sure we don't have to download the data every time we come back to Colab:\n",
        "* Download the data to the attached Google Drive if it doesn't already exists\n",
        "* Copy the data to the Google drive if it isn't already there\n",
        "* If the data already exists on Google Drive We'll import it\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Some information about the data:\n",
        "* We are dealing with unstructured data (images), so it is probably best we use deeep learning/transfer learning.\n",
        "* There are 120 breeds of dogs, this means there are 120 different classes).\n",
        "* Around 10,000+ images in the training set (these images have labels)\n",
        "* Around 10,000+ images in the test set\n"
      ],
      "metadata": {
        "id": "0VwaLo79sNPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick timestamp\n",
        "import datetime\n",
        "print(f\"Notebook last run: {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2DNaKLF_Dye",
        "outputId": "573caae4-8ae6-4368-d512-dacdbc61c64d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook last run: 2025-04-30 19:42:26.226512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and check if we have GPU access\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "device_list = tf.config.list_physical_devices()\n",
        "if \"GPU\" in [device.device_type for device in device_list]:\n",
        "  print(f\"[INFO] TensorFlow has GPU available to use.\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")\n",
        "else:\n",
        "  print(f\"[INFO] TensorFlow does not have GPU available to use. Models may take a while to train.\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbd2DEh0_Xu5",
        "outputId": "2d919af6-bfa6-4bb9-f309-37bc5e7d13b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "[INFO] TensorFlow does not have GPU available to use. Models may take a while to train.\n",
            "[INFO] Accessible devices:\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the data\n",
        "Check if the target files exist in Google Drive and copy them to Colab. If the files doesn't exist, download them."
      ],
      "metadata": {
        "id": "0OYi08W4_7v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive (this will bring up a pop-up to sign-in/authenticate)\n",
        "# Note: This step is specifically for Google Colab, if you're working locally, you may need a different setup\n",
        "# drive.mount(\"/content/drive\")\n",
        "\n",
        "# 2. Setup constants\n",
        "# Note: For constants like this, you'll often see them created as variables with all capitals\n",
        "TARGET_DRIVE_PATH = Path(\"drive/MyDrive/Dog_Vision/Data\")\n",
        "TARGET_FILES = [\"images.tar\", \"annotation.tar\", \"lists.tar\"]\n",
        "TARGET_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs\"\n",
        "\n",
        "# 3. Setup local path\n",
        "local_dir = Path(\"dog_vision_data\")\n",
        "\n",
        "# 4. Check if the target files exist in Google Drive, if so, copy them to Google Colab\n",
        "if all((TARGET_DRIVE_PATH / file).is_file() for file in TARGET_FILES):\n",
        "  print(f\"[INFO] Copying Dog Vision files from Google Drive to local directory...\")\n",
        "  print(f\"[INFO] Source dir: {TARGET_DRIVE_PATH} -> Target dir: {local_dir}\")\n",
        "  !cp -r {TARGET_DRIVE_PATH} {local_dir}\n",
        "  print(\"[INFO] Good to go!\")\n",
        "\n",
        "else:\n",
        "  # 5. If the files don't exist in Google Drive, download them\n",
        "  print(f\"[INFO] Target files not found in Google Drive.\")\n",
        "  print(f\"[INFO] Downloading the target files... this shouldn't take too long...\")\n",
        "  for file in TARGET_FILES:\n",
        "    # wget is short for \"world wide web get\", as in \"get a file from the web\"\n",
        "    # -nc or --no-clobber = don't download files that already exist locally\n",
        "    # -P = save the target file to a specified prefix, in our case, local_dir\n",
        "    !wget -nc {TARGET_URL}/{file} -P {local_dir} # the \"!\" means to execute the command on the command line rather than in Python\n",
        "\n",
        "  print(f\"[INFO] Saving the target files to Google Drive, so they can be loaded later...\")\n",
        "\n",
        "  # 6. Ensure target directory in Google Drive exists\n",
        "  TARGET_DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # 7. Copy downloaded files to Google Drive (so we can use them later and not have to re-download them)\n",
        "  !cp -r {local_dir}/* {TARGET_DRIVE_PATH}/"
      ],
      "metadata": {
        "id": "eHwSjZ_6ABjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the files are exist\n",
        "if local_dir.exists():\n",
        "  print(str(local_dir) + \"/\")\n",
        "  for item in local_dir.iterdir():\n",
        "    print(\"  \", item.name)"
      ],
      "metadata": {
        "id": "_jQbOkfWB6p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untar the images, notes/tags\n",
        "!tar -xf {local_dir}/images.tar -C {local_dir}\n",
        "!tar -xf {local_dir}/annotation.tar -C {local_dir}\n",
        "!tar -xf {local_dir}/lists.tar -C {local_dir}\n"
      ],
      "metadata": {
        "id": "J6lD7f_ICqt8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got some new files.\n",
        "Specifically:\n",
        "\n",
        "* `train_list.mat` - a list of all the training set images.\n",
        "* `test_list.mat` - a list of all the testing set images.\n",
        "* `Images/` - a folder containing all of the images of dogs.\n",
        "* `Annotation/` - a folder containing all of the annotations for each image.\n",
        "* `file_list.mat` - a list of all the files (training and test list combined).\n"
      ],
      "metadata": {
        "id": "D2NzvDlJDoxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data\n",
        "Before we build a model, it's good to explore the data to see what kind of data we're working with. For example:\n",
        "* **Check at least 100+ random samples** if you have a large dataset.\n",
        "* **Visualize!**\n",
        "* **Check the distribution and other statistics.** How many samples are there? In a classification problem, how many classes and labels per class are there? etc."
      ],
      "metadata": {
        "id": "81MY3j-dFu6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the files lists"
      ],
      "metadata": {
        "id": "E0vUvt97MgSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the MATLAB files\n",
        "import scipy\n",
        "\n",
        "# Open lists of train and test .mat\n",
        "train_list = scipy.io.loadmat(Path(local_dir, \"train_list.mat\"))\n",
        "test_list = scipy.io.loadmat(Path(local_dir, \"test_list.mat\"))\n",
        "file_list = scipy.io.loadmat(Path(local_dir, \"file_list.mat\"))\n",
        "\n",
        "# Let's inspect the output and type of the train_list\n",
        "train_list, type(train_list)"
      ],
      "metadata": {
        "id": "y6uzipa-EOeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the keys of the train_list dictionary\n",
        "train_list.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5TV2aFzKXAh",
        "outputId": "f8fe35e1-fc8c-4aee-ab3c-ebda42fec802"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['__header__', '__version__', '__globals__', 'file_list', 'annotation_list', 'labels'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of the file_list key\n",
        "print(f\"Number of files in training list: {len(train_list['file_list'])}\")\n",
        "print(f\"Number of files in testing list: {len(test_list['file_list'])}\")\n",
        "print(f\"Number of files in full list: {len(file_list['file_list'])}\")"
      ],
      "metadata": {
        "id": "RYheiPqvLwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 20580 images total splitted in 60/40 ratio between train and test."
      ],
      "metadata": {
        "id": "j4l5Zl_xMDuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the file_list key more\n",
        "train_list['file_list']\n"
      ],
      "metadata": {
        "id": "Hvf96EWAMsfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single filename\n",
        "train_list['file_list'][0][0][0]"
      ],
      "metadata": {
        "id": "nvNOkSshNS_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a Python list of all file names for each list\n",
        "train_file_list = list([item[0][0] for item in train_list[\"file_list\"]])\n",
        "test_file_list = list([item[0][0] for item in test_list[\"file_list\"]])\n",
        "full_file_list = list([item[0][0] for item in file_list[\"file_list\"]])\n",
        "\n",
        "len(train_file_list), len(test_file_list), len(full_file_list)"
      ],
      "metadata": {
        "id": "eJeb59hwNhfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some random samples\n",
        "import random\n",
        "\n",
        "random.sample(train_file_list, k=10)"
      ],
      "metadata": {
        "id": "aXkS0wOtN-kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that the training set and the test set doesn't have common items"
      ],
      "metadata": {
        "id": "tHWKdn36RFqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many files in the training set intersect with the testing set?\n",
        "len(set(train_file_list).intersection(test_file_list))"
      ],
      "metadata": {
        "id": "4n4VU746RCNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uzvP409-BkDkfGOrePIsP57TDqw_57Kb",
      "authorship_tag": "ABX9TyONLlyVZV3jRgKOcgHLLQ56",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzsolt68/DogVision/blob/main/dog_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-end Multi-class Dog Breed Classification (v2)\n",
        "\n",
        "Building an end-to-end multi-class image classifier using TensorFlow\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Identifying the breed of a dog from a given image\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "We're going to use the Stanford Dogs dataset, which is available from several sources:\n",
        "* The original project website: http://vision.stanford.edu/aditya86/ImageNetDogs/\n",
        "* Inside the Tensorflow datasets: https://www.tensorflow.org/datasets/catalog/stanford_dogs\n",
        "* On Kaggle: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
        "\n",
        "## 3. Using the data\n",
        "\n",
        "To make sure we don't have to download the data every time we come back to Colab:\n",
        "* Download the data to the attached Google Drive if it doesn't already exists\n",
        "* Copy the data to the Google drive if it isn't already there\n",
        "* If the data already exists on Google Drive We'll import it\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Some information about the data:\n",
        "* We are dealing with unstructured data (images), so it is probably best we use deeep learning/transfer learning.\n",
        "* There are 120 breeds of dogs, this means there are 120 different classes).\n",
        "* Around 10,000+ images in the training set (these images have labels)\n",
        "* Around 10,000+ images in the test set\n"
      ],
      "metadata": {
        "id": "0VwaLo79sNPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick timestamp\n",
        "import datetime\n",
        "print(f\"Notebook last run: {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2DNaKLF_Dye",
        "outputId": "e2c631e4-5b56-48c4-e673-a08792f38251"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook last run: 2025-05-11 15:26:18.489551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and check if we have GPU access\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "device_list = tf.config.list_physical_devices()\n",
        "if \"GPU\" in [device.device_type for device in device_list]:\n",
        "  print(f\"[INFO] TensorFlow has GPU available to use.\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")\n",
        "else:\n",
        "  print(f\"[INFO] TensorFlow does not have GPU available to use. Models may take a while to train.\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")"
      ],
      "metadata": {
        "id": "lbd2DEh0_Xu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the data\n",
        "Check if the target files exist in Google Drive and copy them to Colab. If the files doesn't exist, download them."
      ],
      "metadata": {
        "id": "0OYi08W4_7v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive (this will bring up a pop-up to sign-in/authenticate)\n",
        "# Note: This step is specifically for Google Colab, if you're working locally, you may need a different setup\n",
        "# drive.mount(\"/content/drive\")\n",
        "\n",
        "# 2. Setup constants\n",
        "# Note: For constants like this, you'll often see them created as variables with all capitals\n",
        "TARGET_DRIVE_PATH = Path(\"drive/MyDrive/Dog_Vision/Data\")\n",
        "TARGET_FILES = [\"images.tar\", \"annotation.tar\", \"lists.tar\"]\n",
        "TARGET_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs\"\n",
        "\n",
        "# 3. Setup local path\n",
        "local_dir = Path(\"dog_vision_data\")\n",
        "\n",
        "# 4. Check if the target files exist in Google Drive, if so, copy them to Google Colab\n",
        "if all((TARGET_DRIVE_PATH / file).is_file() for file in TARGET_FILES):\n",
        "  print(f\"[INFO] Copying Dog Vision files from Google Drive to local directory...\")\n",
        "  print(f\"[INFO] Source dir: {TARGET_DRIVE_PATH} -> Target dir: {local_dir}\")\n",
        "  !cp -r {TARGET_DRIVE_PATH} {local_dir}\n",
        "  print(\"[INFO] Good to go!\")\n",
        "\n",
        "else:\n",
        "  # 5. If the files don't exist in Google Drive, download them\n",
        "  print(f\"[INFO] Target files not found in Google Drive.\")\n",
        "  print(f\"[INFO] Downloading the target files... this shouldn't take too long...\")\n",
        "  for file in TARGET_FILES:\n",
        "    # wget is short for \"world wide web get\", as in \"get a file from the web\"\n",
        "    # -nc or --no-clobber = don't download files that already exist locally\n",
        "    # -P = save the target file to a specified prefix, in our case, local_dir\n",
        "    !wget -nc {TARGET_URL}/{file} -P {local_dir} # the \"!\" means to execute the command on the command line rather than in Python\n",
        "\n",
        "  print(f\"[INFO] Saving the target files to Google Drive, so they can be loaded later...\")\n",
        "\n",
        "  # 6. Ensure target directory in Google Drive exists\n",
        "  TARGET_DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # 7. Copy downloaded files to Google Drive (so we can use them later and not have to re-download them)\n",
        "  !cp -r {local_dir}/* {TARGET_DRIVE_PATH}/"
      ],
      "metadata": {
        "id": "eHwSjZ_6ABjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the files are exist\n",
        "if local_dir.exists():\n",
        "  print(str(local_dir) + \"/\")\n",
        "  for item in local_dir.iterdir():\n",
        "    print(\"  \", item.name)"
      ],
      "metadata": {
        "id": "_jQbOkfWB6p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untar the images, notes/tags\n",
        "!tar -xf {local_dir}/images.tar -C {local_dir}\n",
        "!tar -xf {local_dir}/annotation.tar -C {local_dir}\n",
        "!tar -xf {local_dir}/lists.tar -C {local_dir}\n"
      ],
      "metadata": {
        "id": "J6lD7f_ICqt8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got some new files.\n",
        "Specifically:\n",
        "\n",
        "* `train_list.mat` - a list of all the training set images.\n",
        "* `test_list.mat` - a list of all the testing set images.\n",
        "* `Images/` - a folder containing all of the images of dogs.\n",
        "* `Annotation/` - a folder containing all of the annotations for each image.\n",
        "* `file_list.mat` - a list of all the files (training and test list combined).\n"
      ],
      "metadata": {
        "id": "D2NzvDlJDoxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the data\n",
        "Before we build a model, it's good to explore the data to see what kind of data we're working with. For example:\n",
        "* **Check at least 100+ random samples** if you have a large dataset.\n",
        "* **Visualize!**\n",
        "* **Check the distribution and other statistics.** How many samples are there? In a classification problem, how many classes and labels per class are there? etc."
      ],
      "metadata": {
        "id": "81MY3j-dFu6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the files lists"
      ],
      "metadata": {
        "id": "E0vUvt97MgSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the MATLAB files\n",
        "import scipy\n",
        "\n",
        "# Open lists of train and test .mat\n",
        "train_list = scipy.io.loadmat(Path(local_dir, \"train_list.mat\"))\n",
        "test_list = scipy.io.loadmat(Path(local_dir, \"test_list.mat\"))\n",
        "file_list = scipy.io.loadmat(Path(local_dir, \"file_list.mat\"))\n",
        "\n",
        "# Let's inspect the output and type of the train_list\n",
        "train_list, type(train_list)"
      ],
      "metadata": {
        "id": "y6uzipa-EOeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the keys of the train_list dictionary\n",
        "train_list.keys()"
      ],
      "metadata": {
        "id": "v5TV2aFzKXAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of the file_list key\n",
        "print(f\"Number of files in training list: {len(train_list['file_list'])}\")\n",
        "print(f\"Number of files in testing list: {len(test_list['file_list'])}\")\n",
        "print(f\"Number of files in full list: {len(file_list['file_list'])}\")"
      ],
      "metadata": {
        "id": "RYheiPqvLwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 20580 images total splitted in 60/40 ratio between train and test."
      ],
      "metadata": {
        "id": "j4l5Zl_xMDuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the file_list key more\n",
        "train_list['file_list']\n"
      ],
      "metadata": {
        "id": "Hvf96EWAMsfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single filename\n",
        "train_list['file_list'][0][0][0]"
      ],
      "metadata": {
        "id": "nvNOkSshNS_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a Python list of all file names for each list\n",
        "train_file_list = list([item[0][0] for item in train_list[\"file_list\"]])\n",
        "test_file_list = list([item[0][0] for item in test_list[\"file_list\"]])\n",
        "full_file_list = list([item[0][0] for item in file_list[\"file_list\"]])\n",
        "\n",
        "len(train_file_list), len(test_file_list), len(full_file_list)"
      ],
      "metadata": {
        "id": "eJeb59hwNhfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some random samples\n",
        "import random\n",
        "\n",
        "random.sample(train_file_list, k=10)"
      ],
      "metadata": {
        "id": "aXkS0wOtN-kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that the training set and the test set doesn't have common items"
      ],
      "metadata": {
        "id": "tHWKdn36RFqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many files in the training set intersect with the testing set?\n",
        "len(set(train_file_list).intersection(test_file_list))"
      ],
      "metadata": {
        "id": "4n4VU746RCNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the Annotation folder"
      ],
      "metadata": {
        "id": "uKTF4C_F_kAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir(f\"{local_dir}/Annotation\")[:10]"
      ],
      "metadata": {
        "id": "QtFhompu_oNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are directories with dog breed names with several numbered files inside.\n",
        "Each of the numbered files contains a HTML version.\n",
        "For example, `Annotation/n02085620-Chihuahua/n02085620_10074`:\n",
        "\n",
        "```\n",
        "<annotation>\n",
        "\t<folder>02085620</folder>\n",
        "\t<filename>n02085620_10074</filename>\n",
        "\t<source>\n",
        "\t\t<database>ImageNet database</database>\n",
        "\t</source>\n",
        "\t<size>\n",
        "\t\t<width>333</width>\n",
        "\t\t<height>500</height>\n",
        "\t\t<depth>3</depth>\n",
        "\t</size>\n",
        "\t<segment>0</segment>\n",
        "\t<object>\n",
        "\t\t<name>Chihuahua</name>\n",
        "\t\t<pose>Unspecified</pose>\n",
        "\t\t<truncated>0</truncated>\n",
        "\t\t<difficult>0</difficult>\n",
        "\t\t<bndbox>\n",
        "\t\t\t<xmin>25</xmin>\n",
        "\t\t\t<ymin>10</ymin>\n",
        "\t\t\t<xmax>276</xmax>\n",
        "\t\t\t<ymax>498</ymax>\n",
        "\t\t</bndbox>\n",
        "\t</object>\n",
        "</annotation>\n",
        "```\n",
        "\n",
        "The fields include the name and the size of the image, the label of the object, and where it is insid ethe image (bounding box)."
      ],
      "metadata": {
        "id": "nsMEjIOMBeIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function to check the number of subfolders inside the `Annotation` folder (there should be 120 subfolder, one for each dog breed)."
      ],
      "metadata": {
        "id": "Z0thxTFsFt5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def count_subfolders(path: str) -> int:\n",
        "  \"\"\"\n",
        "    Count the number of subfolders in a given directory.\n",
        "\n",
        "    Args:\n",
        "    path (str): The path to the directory in which to count subfolders.\n",
        "\n",
        "    Returns:\n",
        "    int: The number of subfolders in the specified directory.\n",
        "\n",
        "    Examples:\n",
        "    >>> count_subfolders('/path/to/directory')\n",
        "    3  # if there are 3 subfolders in the specified directory\n",
        "  \"\"\"\n",
        "  return len([item for item in Path(path).iterdir() if item.is_dir()])\n",
        "\n",
        "annotation_path = f\"{local_dir}/Annotation\"\n",
        "folder_count = count_subfolders(annotation_path)\n",
        "print(f\"Number of subfolders in {annotation_path}: {folder_count}\")"
      ],
      "metadata": {
        "id": "yAddT9NZGOCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 120 subfolder of annotations, one for each class of dog.\n",
        "\n",
        "But it looks like the class names are already in the filepaths."
      ],
      "metadata": {
        "id": "tBdXy3JTH1qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View a single training file pathname\n",
        "train_file_list[0]"
      ],
      "metadata": {
        "id": "vtXeZ3ygIJ-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we know, that image `n02085620_5927.jpg` should contain a `Chihuahua`.\n",
        "Let's check."
      ],
      "metadata": {
        "id": "8uf0Y7bQIZYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(Path(f\"{local_dir}/Images/\", train_file_list[0]))"
      ],
      "metadata": {
        "id": "qlbcZMcaItBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the Images folder\n",
        "\n",
        "We know that the image file names come in the format `class_name/image_name`, for example, `n02085620-Chihuahua/n02085620_5927.jpg`.\n",
        "\n",
        "To make things a little simpler, let's create the following:\n",
        "\n",
        "1. A mapping from folder name -> class name in dictionary form, for example, `{'n02113712-miniature_poodle': 'miniature_poodle',  'n02092339-Weimaraner': 'weimaraner',  'n02093991-Irish_terrier': 'irish_terrier'...}`. This will help us when visualizing our data from its original folder.\n",
        "2. A list of all unique dog class names with simple formatting, for example, `['affenpinscher',  'afghan_hound',  'african_hunting_dog',  'airedale',  'american_staffordshire_terrier'...]`.\n"
      ],
      "metadata": {
        "id": "sp5j3TwiJG27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all image folders\n",
        "image_folders = os.listdir(f\"{local_dir}/Images\")\n",
        "image_folders[:10]"
      ],
      "metadata": {
        "id": "lkp3UglBKPor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a foldername -> class name dictionary\n",
        "folder_to_class_dictionary = {}\n",
        "for folder_name in image_folders:\n",
        "  class_name = folder_name.split(\"-\")[1].lower().replace(\"_\", \" \")\n",
        "  folder_to_class_dictionary[folder_name] = class_name\n",
        "\n",
        "# Make sure there are 120 entries in the dictionary\n",
        "assert len(folder_to_class_dictionary) == 120"
      ],
      "metadata": {
        "id": "oAyn-inWKmRm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(folder_to_class_dictionary.items())[:10]"
      ],
      "metadata": {
        "id": "Sgto11W6LQR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of unique dog names\n",
        "dog_names = sorted(list(set(folder_to_class_dictionary.values())))\n",
        "dog_names[:10]"
      ],
      "metadata": {
        "id": "riHYTYLPLjdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got:\n",
        "- a mapping from a folder name to a class name: `folder_to_class_dictionary`\n",
        "- a list of unique dog breeds: `dog_names`"
      ],
      "metadata": {
        "id": "T99UjGd-L3Yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize a group of random images\n",
        "\n",
        "Create a function that takes a list of image paths and randomly selects 10 paths to display.\n",
        "The function will:\n",
        "1. Take a list of image paths as input.\n",
        "2. Creat a grid of Matplotlib plots (e.g. 2x5)\n",
        "3. Using `random.sample()`, selects 10 image paths from the input list.\n",
        "4. Iterate through the flattened axes via `axes.flat` which is a reference to the attribute `numpy.ndarray.flat`.\n",
        "5. Extract the sample path from the list of samples.\n",
        "6. Get the sample title from the parent folder of the path using `Path.parent.stem` and then extract the formatted dog breed name by indexing `folder_to_class_name_dict`.\n",
        "7. Read the image with `plt.imread()` and show it on the target ax with `ax.imshow()`.\n",
        "8. Set the title of the plot to the parent folder name with `ax.set_title()` and turn the axis marks of with `ax.axis(\"off\")` (this makes for pretty plots).\n",
        "9. Show the plot with `plt.show()`."
      ],
      "metadata": {
        "id": "tb5kV9IqMtJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_10_random_images(image_paths: List[Path], extract_title: bool = True) -> None:\n",
        "  \"\"\"\n",
        "    Plots 10 random images from a list of image paths.\n",
        "\n",
        "    Args:\n",
        "    image_paths (List[Path]): A list of image paths to plot.\n",
        "    extract_title (bool): Whether to extract the title from the image path\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  # Setup a grid of plots\n",
        "  fig, axes = plt.subplots(ncols=5, nrows=2, figsize=(20, 10))\n",
        "\n",
        "  # Get a list of random image paths\n",
        "  samples = random.sample(image_paths, k=10)\n",
        "\n",
        "  # Iterate through the flattened axes and corresponding image paths\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "    # Get the image path\n",
        "    image_path = samples[i]\n",
        "    # Extract the parent directory name to use as the title (if neccesary)\n",
        "    if extract_title:\n",
        "      title = folder_to_class_dictionary[image_path.parent.stem]\n",
        "    else:\n",
        "      title = image_path.parent.stem\n",
        "\n",
        "    # Read the image\n",
        "    ax.imshow(plt.imread(image_path))\n",
        "    # Set the title\n",
        "    ax.set_title(title)\n",
        "    # Turn the axis off\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "plot_10_random_images(image_paths=[Path(f\"{local_dir}/Images/\") / path for path in train_file_list])\n"
      ],
      "metadata": {
        "id": "OA9A-nBbOTU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exploring the distribution of the data\n",
        "\n",
        "How many images of dog we have per breed?\n",
        "\n",
        "A balanced distribution would mean, we have roughly the same number of images of every breed (e.g. 100 images per breed)\n",
        "\n",
        "Let's see, how many images we have per breed? Write e function, that counts the images in a given directory:\n",
        "\n",
        "1. Take in a target directory/folder.\n",
        "2. Create a list of all the subdirectories/subfolders in the target folder.\n",
        "3. Create an empty list, `image_class_counts` to append subfolders and their counts to.\n",
        "4. Iterate through all of the subdirectories.\n",
        "5. Get the class name of the target folder as the name of the folder.\n",
        "6. Count the number of images in the target folder using the length of the list of image paths (we can get these with `Path().rglob(*.jpg)` where `*.jpg` means \"all files with the extension `.jpg`\".\n",
        "7. Append a dictionary of `{\"class_name\": class_name, \"image_count\": image_count}` to the `image_class_counts` list (we create a list of dictionaries so we can turn this into a pandas DataFrame).\n",
        "8. Return the `image_class_counts` list."
      ],
      "metadata": {
        "id": "r_-3lxWJSn1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of image counts\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "\n",
        "def count_images_in_subfolders(target_dir: str) -> List[Dict[str, int]]:\n",
        "  \"\"\"\n",
        "    Counts the number of JPEG images in each subfolder in a given directory.\n",
        "    Each subdirectory is assumed to represent a class, and the function counts\n",
        "    the number of '.jpg' files within each one. The result is a list of\n",
        "    dictionaries with the class name and corresponding image count.\n",
        "\n",
        "    Args:\n",
        "    target_dir (str): The path to the directory in which to count\n",
        "\n",
        "    Returns:\n",
        "    List[Dict[str, int]]: A list of dictionaries with 'class_name' and 'image_count' for each subdirectory.\n",
        "\n",
        "    Examples:\n",
        "        >>> count_images_in_subdirs('/path/to/directory')\n",
        "        [{'class_name': 'beagle', 'image_count': 50}, {'class_name': 'poodle', 'image_count': 60}]\n",
        "  \"\"\"\n",
        "  # Create a list of all the subfolders in the target directory\n",
        "  image_dir = Path(target_dir)\n",
        "  subfolders = [folder for folder in image_dir.iterdir() if folder.is_dir()]\n",
        "\n",
        "  # Create an empty list to append image counts\n",
        "  image_class_counts = []\n",
        "\n",
        "  # Iterate through all of the subfolders\n",
        "  for subfolder in subfolders:\n",
        "    # Get the class name of the target folder as the name of the folder\n",
        "    class_name = subfolder.name\n",
        "\n",
        "    # Count the number of images in the target folder\n",
        "    image_count = len(list(subfolder.rglob(\"*.jpg\")))\n",
        "\n",
        "    # Append a dictionary of class name and image count to count list\n",
        "    image_class_counts.append({\"class_name\": class_name, \"image_count\": image_count})\n",
        "\n",
        "  # Return the count list\n",
        "  return image_class_counts\n"
      ],
      "metadata": {
        "id": "YHX7QyGjU_p3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the function on the target directory and view the first few indexes"
      ],
      "metadata": {
        "id": "pPpSJ1DWW5qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_class_counts = count_images_in_subfolders(f\"{local_dir}/Images\")\n",
        "image_class_counts[:10]"
      ],
      "metadata": {
        "id": "NrKbvvCUXDGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turn the `image_class_count` variable to a pandas `DataFrame`.\n",
        "\n",
        "Sort the `DataFrame` by `image_count`."
      ],
      "metadata": {
        "id": "0ZXcS99mXRo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "image_counts_dataframe = pd.DataFrame(image_class_counts).sort_values(\"image_count\", ascending=False)\n",
        "image_counts_dataframe.head()"
      ],
      "metadata": {
        "id": "1W49SOEjXqKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map the `class_name` column to the `folder_to_class_dictionary` to easier read."
      ],
      "metadata": {
        "id": "h-xF_ev3YJ_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_counts_dataframe[\"class_name\"] = image_counts_dataframe[\"class_name\"].map(folder_to_class_dictionary)\n",
        "image_counts_dataframe.head()"
      ],
      "metadata": {
        "id": "NLiMgXnuYiAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the distribution of the data by turning the DataFrame into a plot."
      ],
      "metadata": {
        "id": "IbGEZAt_YwD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "image_counts_dataframe.plot(kind=\"bar\",\n",
        "                            x=\"class_name\",\n",
        "                            y=\"image_count\",\n",
        "                            legend=False,\n",
        "                            ax=plt.gca())\n",
        "plt.title(\"Images per Dog Breed\")\n",
        "plt.xlabel(\"Dog Breed\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xticks(rotation=90, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZoPWS3bNZCFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some statistics about the DataFrame\n",
        "image_counts_dataframe.describe()"
      ],
      "metadata": {
        "id": "n4gVSAuIaR0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating training and test data split directories"
      ],
      "metadata": {
        "id": "MP_UMK2w94hF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After exploring the data, we need to create a training and test data splits. The original dataset already comes with this split, so we stick with these. But we also creating a smaller training set (about 10% of the original training set) for faster experimentation."
      ],
      "metadata": {
        "id": "g5unE1jS-hY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create:\n",
        "\n",
        "- a folder for training images `dog_vision_data/images/train`\n",
        "- a folder for test images `dog_vision_data/images/test`\n",
        "- inside each directory, make directories for each dog breed"
      ],
      "metadata": {
        "id": "Q3YQH4W9_bzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Target directory for image splits\n",
        "image_split_directory = Path(local_dir, \"images_split\")\n",
        "\n",
        "# Training and test directories\n",
        "train_dir = image_split_directory / \"train\"\n",
        "test_dir = image_split_directory / \"test\"\n",
        "\n",
        "# Create the target directories if it doesn't exist\n",
        "train_dir.mkdir(parents=True, exist_ok=True)\n",
        "test_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Directory {train_dir} is exists.\")\n",
        "print(f\"Directory {test_dir} is exists.\")\n",
        "\n",
        "# Make folders for each dog breeds\n",
        "for dog_name in dog_names:\n",
        "  # Make training folder\n",
        "  dog_train_dir = train_dir / dog_name\n",
        "  dog_train_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Make test folder\n",
        "  dog_test_dir = test_dir / dog_name\n",
        "  dog_test_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Check if 120 subfolder in each folder\n",
        "assert count_subfolders(train_dir) == len(dog_names)\n",
        "assert count_subfolders(test_dir) == len(dog_names)"
      ],
      "metadata": {
        "id": "dz4xvB0ZBUgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the first 10 directories in the training directory\n",
        "sorted([str(dir_name) for dir_name in train_dir.iterdir() if dir_name.is_dir()])[:10]"
      ],
      "metadata": {
        "id": "lgUDeVTVEhXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function which will copy images from the `Images` folder into the respective directories inside `images_split/train` and `images_split/test`\n",
        "\n",
        "Specifically:\n",
        "\n",
        "1. Take in a list of source files to copy (e.g. `train_file_list`) and a target directory to copy files to.\n",
        "2. Iterate through the list of sources files to copy (use `tqdm` which comes installed with Google Colab to create a progress bar of how many files have been copied).\n",
        "3. Convert the source file path to a `Path` object.\n",
        "4. Split the source file path and create a `Path` object for the destination folder (e.g. \"n02112018-Pomeranian\" -> \"pomeranian\").\n",
        "5. Get the target file name (e.g. \"n02112018-Pomeranian/n02112018_6208.jpg\" -> \"n02112018_6208.jpg\").\n",
        "6. Create a destination path for the source file to be copied to (e.g. `images_split/train/pomeranian/n02112018_6208.jpg`).\n",
        "7. Ensure the destination directory exists, similar to the step we took in the previous section (you can't copy files to a directory that doesn't exist).\n",
        "8. Print out the progress of copying (if necessary).\n",
        "9. Copy the source file to the destination using Python's `shutil.copy2(src, dst)`."
      ],
      "metadata": {
        "id": "9j7dAHCNFKIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from shutil import copy2\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def copy_files_to_target_directory(file_list: List[str],\n",
        "                                   target_dir: str,\n",
        "                                   images_dir: str = \"dog_vision_data/Images\",\n",
        "                                   verbose: bool = False) -> None:\n",
        "  \"\"\"\n",
        "  Copies a list of files from the images directory to a target directory.\n",
        "\n",
        "  Parameters:\n",
        "  file_list (list[str]): A list of file paths to copy.\n",
        "  target_dir (str): The destination directory path where files will be copied.\n",
        "  images_dir (str, optional): The directory path where the images are currently stored. Defaults to 'dog_vision_data/Images'.\n",
        "  verbose (bool, optional): If set to True, the function will print out the file paths as they are being copied. Defaults to False.\n",
        "\n",
        "  Returns:\n",
        "  None\n",
        "  \"\"\"\n",
        "  # Iterate through source files\n",
        "  for file in tqdm(file_list):\n",
        "    # Convert file path to Path object\n",
        "    source_file_path = Path(images_dir) / Path(file)\n",
        "\n",
        "    # Split the file path and create a Path object for destination folder\n",
        "    file_class_name = folder_to_class_dictionary[Path(file).parts[0]]\n",
        "\n",
        "    # Get the name of the image\n",
        "    file_image_name = Path(file).name\n",
        "\n",
        "    # Create destination path\n",
        "    destination_path = Path(target_dir) / file_class_name / file_image_name\n",
        "\n",
        "    # Check if destination directory exists\n",
        "    destination_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Print out copy message, if neccesary\n",
        "    if verbose:\n",
        "      print(f\"[INFO] Copying: {source_file_path} to {destination_path}\")\n",
        "\n",
        "    # Copy the file to the destination\n",
        "    copy2(source_file_path, destination_path)"
      ],
      "metadata": {
        "id": "0uX2bq4YGppZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the copy function by copying files from `train_file_list` to `train_dir`"
      ],
      "metadata": {
        "id": "7ZiTbbCOJdut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files_to_target_directory(file_list=train_file_list,\n",
        "                               target_dir=train_dir,\n",
        "                               verbose=False)"
      ],
      "metadata": {
        "id": "zyJjptX0JZ3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy files from `test_file_list` to `test_dir`"
      ],
      "metadata": {
        "id": "-BUudrl9KLce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files_to_target_directory(file_list=test_file_list,\n",
        "                               target_dir=test_dir,\n",
        "                               verbose=False)"
      ],
      "metadata": {
        "id": "m7ulL-KHKSXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the number of files in the `train_file_list` is the same as the number of images in the `train_dir` (and also check the test files)."
      ],
      "metadata": {
        "id": "oNMemZSTKfN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all .jpg file paths in train and test image folders\n",
        "train_image_paths = list(train_dir.rglob(\"*.jpg\"))\n",
        "test_image_paths = list(test_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "# Make sure the number of images in the train and test directories equals the number of files in the original lists\n",
        "assert len(train_image_paths) == len(train_file_list)\n",
        "assert len(test_image_paths) == len(test_file_list)\n",
        "\n",
        "print(f\"Number of images in {train_dir}: {len(train_image_paths)}\")\n",
        "print(f\"Number of images in {test_dir}: {len(test_image_paths)}\")"
      ],
      "metadata": {
        "id": "_m6oCyALK8WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot some random images from the `train_image_path`"
      ],
      "metadata": {
        "id": "2n0xwSbAMMa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_10_random_images(image_paths=train_image_paths,\n",
        "                      extract_title=False)"
      ],
      "metadata": {
        "id": "E7EW0YhfMWKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a 10% training dataset split"
      ],
      "metadata": {
        "id": "ZDZDsCiRM-Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make model experiments faster, we create a smaller (~10%) training dataset in the `images_split` directory.\n",
        "To make this dataset, we copy a random 10% of the existing training set to a new folder, named `images_split/train_10_percent`."
      ],
      "metadata": {
        "id": "aLnTROs0NSrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the 10% folder\n",
        "train_10_percent_dir = image_split_directory / \"train_10_percent\"\n",
        "train_10_percent_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "PrE-Y7hfOEmk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(image_split_directory)"
      ],
      "metadata": {
        "id": "7RXtZA43OPW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take 10% random sample from the train_image_paths\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "train_image_paths_10_percent = random.sample(population=train_image_paths,\n",
        "                                             k=int(len(train_image_paths) * 0.1))\n",
        "\n",
        "print(f\"Original number of images: {len(train_image_paths)}\")\n",
        "print(f\"Number of images in 10% sample: {len(train_image_paths_10_percent)}\")\n",
        "print(\"First 5 random images in 10% sample:\")\n",
        "train_image_paths_10_percent[:5]"
      ],
      "metadata": {
        "id": "tBb6moktPdID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the 10% random sample to the sample directory"
      ],
      "metadata": {
        "id": "vK-9PK49QPyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for source_file_path in tqdm(train_image_paths_10_percent):\n",
        "  # Create the destination file path\n",
        "  destination_file_and_image_name = Path(*source_file_path.parts[-2:])\n",
        "  destination_path = train_10_percent_dir / destination_file_and_image_name\n",
        "\n",
        "  # Create the target directory if not exists\n",
        "  target_class_dir = destination_path.parent\n",
        "  if not target_class_dir.is_dir():\n",
        "    target_class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Copy the file to the destination\n",
        "  copy2(source_file_path, destination_path)"
      ],
      "metadata": {
        "id": "Wc9Jv6rPQX4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the 10% set distribution and make sure we've got some images for each class."
      ],
      "metadata": {
        "id": "5b3W93nIRbqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count images in the 10% directory\n",
        "train_10_percent_image_class_count  = count_images_in_subfolders(train_10_percent_dir)\n",
        "train_10_percent_image_class_count_df = pd.DataFrame(train_10_percent_image_class_count).sort_values(\"image_count\", ascending=True)\n",
        "train_10_percent_image_class_count_df.head()"
      ],
      "metadata": {
        "id": "3PDBWJ7RRtzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many subfolders are in the 10% directory\n",
        "print(len(train_10_percent_image_class_count_df))"
      ],
      "metadata": {
        "id": "gizQkhiYSPNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the distribution of the 10% training set"
      ],
      "metadata": {
        "id": "Uj1-sEbtSciC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "train_10_percent_image_class_count_df.plot(kind=\"bar\",\n",
        "                                           x=\"class_name\",\n",
        "                                           y=\"image_count\",\n",
        "                                           legend=False,\n",
        "                                           ax=plt.gca())\n",
        "\n",
        "plt.title(\"Images per Dog Breed (10% Sample)\")\n",
        "plt.xlabel(\"Dog Breed\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xticks(rotation=90, fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#"
      ],
      "metadata": {
        "id": "Vx1YIqJSSikn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turning datasets into TensorFlow dataset(s)"
      ],
      "metadata": {
        "id": "zsgBEgxhVrzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert the images to tensors to train the ML model.\n",
        "The reason why we sort the images to the classic image classification format (where the class name is the directory name) is, because TensorFlow offers some utility functions to load data from this format.\n",
        "\n",
        "| Function |\tDescription |\n",
        "|-----------------------------------|-----------------------------------|\n",
        "| tf.keras.utils.image_dataset_from_directory() |\tCreates a tf.data.Dataset from image files in a directory. |\n",
        "| tf.keras.utils.audio_dataset_from_directory() |\tCreates a tf.data.Dataset from audio files in a directory. |\n",
        "| tf.keras.utils.text_dataset_from_directory() |\tCreates a tf.data.Dataset from text files in a directory. |\n",
        "| tf.keras.utils.timeseries_dataset_from_array() |\tCreates a dataset of sliding windows over a timeseries provided as array. |\n",
        "\n",
        "We'll use the `tf.keras.utils.image_dataset_from_directory()` with the following parameters:\n",
        "\n",
        "- `directory` = the target directory we'd like to turn into a `tf.data.Dataset`.\n",
        "- `label_mode` = the kind of labels we'd like to use, in our case it's `\"categorical\"` since we're dealing with a multi-class classification problem (we would use `\"binary\"` if we were working with binary classifcation problem).\n",
        "- `batch_size` = the number of images we'd like our model to see at a time (due to computation limitations, our model won't be able to look at every image at once so we split them into small batches and the model looks at each batch individually), generally 32 is a good value to start, this means our model will look at 32 images at a time (this number is flexible).\n",
        "- `image_size` = the size we'd like to shape our images to before we feed them to our model (height x width).\n",
        "- `shuffle` = whether we'd like our dataset to be shuffled to randomize the order.\n",
        "- `seed` = if we're shuffling the order in a random fashion, do we want that to be reproducible?"
      ],
      "metadata": {
        "id": "WWs_iQtvVydN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make 3 `tf.data.Dataset` for `train`, `test` and `10%_train` datasets."
      ],
      "metadata": {
        "id": "DSsZPYRRZUdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create some constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "\n",
        "# Create 10% train dataset\n",
        "train_10_percent_ds = tf.keras.utils.image_dataset_from_directory(directory=train_10_percent_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  batch_size=BATCH_SIZE,\n",
        "                                                                  image_size=IMG_SIZE,\n",
        "                                                                  shuffle=True,\n",
        "                                                                  seed=SEED)\n",
        "\n",
        "# Create full train dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(directory=train_dir,\n",
        "                                                       label_mode=\"categorical\",\n",
        "                                                       batch_size=BATCH_SIZE,\n",
        "                                                       image_size=IMG_SIZE,\n",
        "                                                       shuffle=True,\n",
        "                                                       seed=SEED)\n",
        "\n",
        "# Create test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(directory=test_dir,\n",
        "                                                      label_mode=\"categorical\",\n",
        "                                                      batch_size=BATCH_SIZE,\n",
        "                                                      image_size=IMG_SIZE,\n",
        "                                                      shuffle=False,\n",
        "                                                      seed=SEED)\n"
      ],
      "metadata": {
        "id": "JPpsoWYQZrZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the 10% dataset\n",
        "train_10_percent_ds"
      ],
      "metadata": {
        "id": "s72zLNbObC1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check a single batch in a dataset\n",
        "image_batch, label_batch = next(iter(train_ds))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "id": "cYgsOuD1bWlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single sample from a batch\n",
        "print(f\"Single image tensor:\\n {image_batch[0]}\\n\")\n",
        "print(f\"Single label tensor:\\n {label_batch[0]}\")\n",
        "print(f\"Single sample class name: {dog_names[tf.argmax(label_batch[0])]}\")\n"
      ],
      "metadata": {
        "id": "vWfu29bWbuRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualizing images from TensorFlow Dataset"
      ],
      "metadata": {
        "id": "JucoTl85ccrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a single image\n",
        "plt.imshow(image_batch[0].numpy().astype(\"uint8\"))\n",
        "plt.title(dog_names[tf.argmax(label_batch[0])])\n",
        "plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "JDOu9D5RcoS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot multiple images\n",
        "\n",
        "# Create multiple subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 10))\n",
        "\n",
        "# Iterate through a single batch and plot images\n",
        "for images, labels in train_ds.take(count=1):\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    ax.set_title(dog_names[tf.argmax(labels[i])])\n",
        "    ax.axis(\"off\")"
      ],
      "metadata": {
        "id": "Z0bV8XOadCjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Getting labels from TensorFlow Datasets"
      ],
      "metadata": {
        "id": "cRQ9Hwq9d28Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first 5 file paths from the training dataset\n",
        "train_ds.file_paths[:5]"
      ],
      "metadata": {
        "id": "OjAVJmKXeI6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names\n",
        "class_names = train_ds.class_names\n",
        "class_names[:5]"
      ],
      "metadata": {
        "id": "KpM1XFQ0eWWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the class names are the same in each dataset\n",
        "assert set(train_10_percent_ds.class_names) == set(train_ds.class_names) == set(test_ds.class_names)"
      ],
      "metadata": {
        "id": "X7syMeAMejmp"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuring the datasets for performance\n",
        "\n",
        "We're going to call three methods on our dataset to optimize it for performance:\n",
        "\n",
        "- `cache()` - Cache the elements in the dataset in memory or a target folder (speeds up loading).\n",
        "- `shuffle()` - Shuffle a set number of samples in preparation for loading (this will mean our samples and batches of samples will be shuffled), for example, setting `shuffle(buffer_size=1000)` will prepare and shuffle 1000 elements of data at a time.\n",
        "- `prefetch()` - Prefetch the next batch of data and prepare it for computation whilst the previous one is being computed on (can scale to multiple prefetches depending on hardware availability). TensorFlow can automatically configure how many elements/batches to prefetch by setting `prefetch(buffer_size=tf.data.AUTOTUNE)`."
      ],
      "metadata": {
        "id": "aKPOURSfezLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Shuffle and optimize performance on training datasets\n",
        "train_10_percent_ds = train_10_percent_ds.cache().shuffle(buffer_size=10*BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "train_ds = train_ds.cache().shuffle(buffer_size=100*BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Don't shuffle the test dataset\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "sLn6STIoffHI"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}